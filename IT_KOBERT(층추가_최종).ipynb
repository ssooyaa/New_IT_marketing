{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssooyaa/New_IT_marketing/blob/main/IT_KOBERT(%EC%B8%B5%EC%B6%94%EA%B0%80_%EC%B5%9C%EC%A2%85).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XfhSrYVwnr3c",
        "outputId": "cf66bed5-3089-40da-cd21-1dc3a2dd0b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1 MB 126.8 MB/s eta 0:00:10tcmalloc: large alloc 1147494400 bytes == 0x3a914000 @  0x7f820cba0615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |█████████████████               | 1055.7 MB 80.1 MB/s eta 0:00:12tcmalloc: large alloc 1434370048 bytes == 0x7ef6a000 @  0x7f820cba0615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |█████████████████████           | 1295.5 MB 1.2 MB/s eta 0:09:45"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |█████████████████████████▎      | 1565.3 MB 112.8 MB/s eta 0:00:04"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 2241208320 bytes == 0x6eb84000 @  0x7f820cba0615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x51b221 0x5b41c5 0x58f49e 0x51837f 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4cfabb 0x517aa0 0x4ba70a 0x538136 0x590055 0x51b180 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51740e 0x58f2a7 0x517947 0x5b41c5 0x58f49e\n",
            "\u001b[K     |██████████████████████████████▌ | 1892.2 MB 111.5 MB/s eta 0:00:01"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 2477817856 bytes == 0x1debf8000 @  0x7f820cba0615 0x58e046 0x4f2e5e 0x4d19df 0x51b31c 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x5b41c5 0x58f49e 0x517947 0x58f2a7 0x517947 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x58f49e 0x51837f 0x5b41c5 0x4ba899 0x4d29f9\n",
            "\u001b[K     |████████████████████████████████| 1982.2 MB 4.8 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6 MB 79.7 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.0\n",
            "  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.1\n",
            "    Uninstalling torch-1.10.1:\n",
            "      Successfully uninstalled torch-1.10.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7A8gM3vMOr9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc6845e-4e6c-4e8a-a233-a769890f3035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.1 MB 255 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2022.9.24)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 7.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.32)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.9)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595758 sha256=a9b5bededd111fdfabdfd89b1f6d2eef33df9947eb2a464a78cfe43ca493eb1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 14.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==3.0.2\n",
            "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 14.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.8.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Downloading tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 77.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 83.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2022.6.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.97)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=cfdf9eb1d0dedf65e31fc68c6204a01915054a265dc871edd10590713dbe2d66\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n"
          ]
        }
      ],
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install torch\n",
        "!pip install transformers==3.0.2\n",
        "!pip install folium==0.2.1\n",
        "!pip install -U --no-cache-dir gdown --pre"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master"
      ],
      "metadata": {
        "id": "CGud4mTCblUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp \n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "9ht6Zchvb7j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kobert\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "#transformers\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup"
      ],
      "metadata": {
        "id": "rAguAuTzdc4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "metadata": {
        "id": "IB6mekHkeetu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT 모델, Vocabulary 불러오기\n",
        "bertmodel, vocab = get_pytorch_kobert_model()"
      ],
      "metadata": {
        "id": "rHVP0Awvfh6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -no-cache-dir gdown --pre"
      ],
      "metadata": {
        "id": "l7cRdiEh_Fhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "myfile = files.upload()"
      ],
      "metadata": {
        "id": "ZPV4kQLII3tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_excel('/content/리뷰_데이터_최종.xlsx')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nkqIBbW5hMMk",
        "outputId": "088609b0-7007-4585-bd18-39258cf65f0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                            comment\n",
              "0      0  메종키츠네 테마 폴드3에서는 적용 불가네요;;; 제일 비싼 라인업에서 사용 불가라니...\n",
              "1      1                                          진짜 너무 이쁘다\n",
              "2      1                                           아 너무 예쁘당\n",
              "3      1  솔직히 이거는 돈 하나도 안아까울듯  브랜드 이미지만 있어도 충분히 감성적일텐데, ...\n",
              "4      1       진짜 너무 예쁘네요ㅠㅠ 워치랑 버즈도 이쁜데 폰 테마 진짜 대박. 너무 이뻐요."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93836a37-6f72-486b-ab50-7be556573ffd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>메종키츠네 테마 폴드3에서는 적용 불가네요;;; 제일 비싼 라인업에서 사용 불가라니...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>진짜 너무 이쁘다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>아 너무 예쁘당</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>솔직히 이거는 돈 하나도 안아까울듯  브랜드 이미지만 있어도 충분히 감성적일텐데, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>진짜 너무 예쁘네요ㅠㅠ 워치랑 버즈도 이쁜데 폰 테마 진짜 대박. 너무 이뻐요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93836a37-6f72-486b-ab50-7be556573ffd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93836a37-6f72-486b-ab50-7be556573ffd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93836a37-6f72-486b-ab50-7be556573ffd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_list = []\n",
        "for q, label in zip(data['comment'], data['label']):\n",
        "  data_tmp = []\n",
        "  data_tmp.append(q)\n",
        "  data_tmp.append(str(label))\n",
        "  \n",
        "  data_list.append(data_tmp)"
      ],
      "metadata": {
        "id": "QtGDaZowiqY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z20INmcPjNFI",
        "outputId": "45647629-2830-466b-9749-ddf2b71acac9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['메종키츠네 테마 폴드3에서는 적용 불가네요;;; 제일 비싼 라인업에서 사용 불가라니;;; 당황스럽네..', '0'],\n",
              " ['진짜 너무 이쁘다', '1'],\n",
              " ['아 너무 예쁘당', '1'],\n",
              " ['솔직히 이거는 돈 하나도 안아까울듯  브랜드 이미지만 있어도 충분히 감성적일텐데, 디테일까지 장난없구나', '1'],\n",
              " ['진짜 너무 예쁘네요ㅠㅠ 워치랑 버즈도 이쁜데 폰 테마 진짜 대박. 너무 이뻐요.', '1']]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train & test 데이터로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset_train, dataset_test = train_test_split(data_list, test_size = 0.25, shuffle=True)"
      ],
      "metadata": {
        "id": "OZBS1rpcjOzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset_train))\n",
        "print(len(dataset_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d06Vq96sjqPn",
        "outputId": "45bf56b7-8eb7-48f8-b90e-1746bfa85e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25629\n",
            "8543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzasxzGwjvfp",
        "outputId": "9867bc80-96ed-4279-8777-2b0c5b3ba179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['좋은 제품 가성비 좋게 잘 구입하여 잘 쓰고 있습니다넘 좋으네요', '1']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 train data와 test data로 나누었다면 각 데이터가\n",
        "# KoBERT 모델의 입력으로 들어갈 수 있는 형태가 되도록 토큰화,\n",
        "# 정수 인코딩, 패딩 등을 해주어야 한다.\n",
        "# 예시 코드에 입력 데이터의 형태가 되도록 해주는 클래스가 있어서\n",
        "# 동일하게 코드를 작성해주었다.\n",
        "class BERTDataset(Dataset):\n",
        "  def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len, pad, pair):\n",
        "    transform = nlp.data.BERTSentenceTransform(\n",
        "        bert_tokenizer,max_seq_length=max_len, pad=pad, pair=pair)\n",
        "    \n",
        "    self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "    self.labels = [np.int32(i[label_idx])for i in dataset]\n",
        "\n",
        "  def __getitem__(self,i):\n",
        "    return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "  def __len__(self):\n",
        "    return (len(self.labels))"
      ],
      "metadata": {
        "id": "38w7z1a0jzDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting parameters\n",
        "max_len = 150\n",
        "batch_size = 32\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1 #그래디언트 클리핑(https://wikidocs.net/61375)\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5"
      ],
      "metadata": {
        "id": "1qGYu2Gkpmov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT28OTi9qjek",
        "outputId": "84099fc6-158b-4f01-b33c-8b3e06c03d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSxdwUu6q9-P",
        "outputId": "8c57fe13-d00e-4c6f-8e20-135b35599a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([   2, 4209, 4158,  517, 5330, 6573, 6441, 4204, 5400, 3942, 1124,\n",
              "        7815, 3942, 3084, 5439, 3867, 5698, 4204, 7074, 5703,    3,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
              " array(21, dtype=int32),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3개의 array가 출력 첫번째 패딩된 시퀀스, 두번째 길이, 타입, 세번째 어텐션 마스크 시퀀스"
      ],
      "metadata": {
        "id": "3o3A9QyArZBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# torch 형식의 dataset을 생성\n",
        "train_dataloader = torch.utils.data.DataLoader(data_train,\n",
        "                                               batch_size=batch_size,\n",
        "                                               num_workers=2)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test,\n",
        "                                               batch_size=batch_size,\n",
        "                                               num_workers=2)"
      ],
      "metadata": {
        "id": "7fWcoMTlrVLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BERTClassifier(nn.Module):\n",
        "  def __init__(self,\n",
        "                bert,\n",
        "                hidden_size = 768,\n",
        "                hidden_size2 = 128,\n",
        "                hidden_size3 = 32,\n",
        "                num_classes=3,\n",
        "                dr_rate=None,\n",
        "                params=None):\n",
        "      super(BERTClassifier, self).__init__()\n",
        "      self.bert = bert\n",
        "      self.dr_rate = dr_rate\n",
        "      self.classifier = nn.Linear(hidden_size , hidden_size2)\n",
        "      self.classifier = nn.Linear(hidden_size , hidden_size3)\n",
        "      if dr_rate:\n",
        "          self.dropout = nn.Dropout(p=dr_rate)\n",
        "      self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "      if dr_rate:\n",
        "          self.dropout = nn.Dropout(p=dr_rate)\n",
        "  \n",
        "  def gen_attention_mask(self, token_ids, valid_length):\n",
        "      attention_mask = torch.zeros_like(token_ids)\n",
        "      for i, v in enumerate(valid_length):\n",
        "          attention_mask[i][:v] = 1\n",
        "      return attention_mask.float()\n",
        "\n",
        "  def forward(self, token_ids, valid_length, segment_ids):\n",
        "      attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "      \n",
        "      _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "      if self.dr_rate:\n",
        "          out = self.dropout(pooler)\n",
        "      else:\n",
        "          out = pooler\n",
        "      return self.classifier(out)"
      ],
      "metadata": {
        "id": "eb3Sl8_Br5nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BERTClassifier(bertmodel,  dr_rate=0.3).to(device)"
      ],
      "metadata": {
        "id": "FkqvXZ_ouuGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]"
      ],
      "metadata": {
        "id": "LvUNP2zuuv3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(f'name:{name}')\n",
        "  print(type(param))\n",
        "  print(f'param.shape:{param.shape}')\n",
        "  print(f'param.requires_grad:{param.requires_grad}')\n",
        "  print(\"=====\")\n"
      ],
      "metadata": {
        "id": "FsNcZ9YMu4ha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f09829-425b-47f5-d62a-fb3413260d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name:bert.embeddings.word_embeddings.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([8002, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.embeddings.position_embeddings.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([512, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.embeddings.token_type_embeddings.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([2, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.embeddings.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.embeddings.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.0.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.1.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.2.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.3.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.4.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.5.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.6.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.7.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.8.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.9.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.10.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.self.query.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.self.query.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.self.key.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.self.key.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.self.value.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.self.value.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.intermediate.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.intermediate.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.output.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 3072])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.output.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.output.LayerNorm.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.encoder.layer.11.output.LayerNorm.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.pooler.dense.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:bert.pooler.dense.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:classifier.weight\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3, 768])\n",
            "param.requires_grad:True\n",
            "=====\n",
            "name:classifier.bias\n",
            "<class 'torch.nn.parameter.Parameter'>\n",
            "param.shape:torch.Size([3])\n",
            "param.requires_grad:True\n",
            "=====\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "#정확도 측정을 위한 함수 정의\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc"
      ],
      "metadata": {
        "id": "3rETY1M6vaZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in tqdm(enumerate(test_dataloader), total=len(test_dataloader)):\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        test_acc += calc_accuracy(out, label)\n",
        "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI5vcTW5wNgh",
        "outputId": "5a7a5566-5072-477f-90e2-ff2b1e29225a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/801 [00:00<01:35,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 1 loss 1.0295279026031494 train acc 0.40625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 202/801 [00:19<00:57, 10.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 201 loss 0.2629401981830597 train acc 0.8406405472636815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 402/801 [00:38<00:38, 10.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 401 loss 0.6020104289054871 train acc 0.8800654613466334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 602/801 [00:57<00:18, 10.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 601 loss 0.27624738216400146 train acc 0.8930948419301165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [01:16<00:00, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 batch id 801 loss 0.7087274789810181 train acc 0.8995154225321795\n",
            "epoch 1 train acc 0.8995154225321795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 267/267 [00:06<00:00, 38.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 test acc 0.9319915126253474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 2/801 [00:00<01:26,  9.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 1 loss 0.16260606050491333 train acc 0.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 202/801 [00:19<00:57, 10.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 201 loss 0.23620550334453583 train acc 0.9319029850746269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 402/801 [00:38<00:37, 10.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 401 loss 0.25159594416618347 train acc 0.9395261845386533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 602/801 [00:57<00:18, 10.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 601 loss 0.029752962291240692 train acc 0.9430636439267887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [01:16<00:00, 10.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 batch id 801 loss 0.6439403891563416 train acc 0.9451305480218691\n",
            "epoch 2 train acc 0.9451305480218691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 267/267 [00:06<00:00, 38.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 2 test acc 0.9299980367282832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 3/801 [00:00<01:17, 10.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 1 loss 0.011346511542797089 train acc 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 203/801 [00:19<00:56, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 201 loss 0.015329113230109215 train acc 0.960976368159204\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 403/801 [00:38<00:37, 10.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 401 loss 0.3573380410671234 train acc 0.9635286783042394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 603/801 [00:57<00:18, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 601 loss 0.033698875457048416 train acc 0.9667741264559068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [01:16<00:00, 10.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 batch id 801 loss 0.28165385127067566 train acc 0.9679616535365276\n",
            "epoch 3 train acc 0.9679616535365276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 267/267 [00:06<00:00, 38.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 3 test acc 0.9234437296121784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 3/801 [00:00<01:20,  9.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 1 loss 0.007663157302886248 train acc 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 203/801 [00:19<00:56, 10.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 201 loss 0.11936495453119278 train acc 0.976523631840796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 403/801 [00:37<00:37, 10.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 401 loss 0.2969716191291809 train acc 0.9797381546134664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 603/801 [00:56<00:18, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 601 loss 0.0051332092843949795 train acc 0.9826331114808652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [01:15<00:00, 10.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 batch id 801 loss 0.24142256379127502 train acc 0.9839223061690129\n",
            "epoch 4 train acc 0.9839223061690129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 267/267 [00:06<00:00, 38.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 4 test acc 0.9376057146309049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 2/801 [00:00<01:25,  9.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 1 loss 0.0036088326014578342 train acc 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 202/801 [00:18<00:55, 10.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 201 loss 0.006993099581450224 train acc 0.9908271144278606\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 402/801 [00:37<00:37, 10.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 401 loss 0.16353753209114075 train acc 0.9910380299251871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 602/801 [00:56<00:19, 10.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 601 loss 0.0035208577755838633 train acc 0.9917325291181365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 801/801 [01:14<00:00, 10.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 batch id 801 loss 0.22550994157791138 train acc 0.9915299840716346\n",
            "epoch 5 train acc 0.9915299840716346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 267/267 [00:06<00:00, 38.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5 test acc 0.940297662196448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "def predict(predict_sentence):\n",
        "\n",
        "  data = [predict_sentence, '0']\n",
        "  dataset_another = [data]\n",
        "\n",
        "  another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "  test_dataloader = torch.utils.data.DataLoader(another_test,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=5)\n",
        "  model.eval()\n",
        "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "    valid_length = valid_length\n",
        "    label = label.long().to(device)\n",
        "\n",
        "    out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "    test_eval = []\n",
        "    for i in out:\n",
        "      logits = i\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "\n",
        "      if np.argmax(logits)==0:\n",
        "        test_eval.append(\"부정\")\n",
        "      elif np.argmax(logits)==1:\n",
        "        test_eval.append(\"긍정\")\n",
        "      elif np.argmax(logits)==2:\n",
        "        test_eval.append(\"중립\")\n",
        "\n",
        "    print(\">> 입력하신 내용에서 \"+ test_eval[0] + \" 입니다.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8gvuwRlwVbX",
        "outputId": "9270e3d7-9899-4e15-9a4b-4087f1f27f5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "def predict(predict_sentence):\n",
        "\n",
        "  data = [predict_sentence, '0']\n",
        "  dataset_another = [data]\n",
        "\n",
        "  another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "  test_dataloader = torch.utils.data.DataLoader(another_test,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=5)\n",
        "  model.eval()\n",
        "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "    valid_length = valid_length\n",
        "    label = label.long().to(device)\n",
        "\n",
        "    out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "    test_eval = []\n",
        "    for i in out:\n",
        "      logits = i\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "\n",
        "      if np.argmax(logits)==0:\n",
        "        test_eval.append(\"부정\")\n",
        "      elif np.argmax(logits)==1:\n",
        "        test_eval.append(\"긍정\")\n",
        "      elif np.argmax(logits)==2:\n",
        "        test_eval.append(\"중립\")\n",
        "\n",
        "    print(\">> 입력하신 내용에서 \"+ test_eval[0] + \" 입니다.\")"
      ],
      "metadata": {
        "id": "dg-lsA-qJC04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict('디자인은 예쁜데... 배터리가')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1D1Ky41ZK5OI",
        "outputId": "c976eaec-21a4-40c3-ac0a-569f75fb2778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> 입력하신 내용에서 중립 입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰화\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "def predict(predict_sentence):\n",
        "\n",
        "  data = [predict_sentence, '0']\n",
        "  dataset_another = [data]\n",
        "\n",
        "  another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "  test_dataloader = torch.utils.data.DataLoader(another_test,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=5)\n",
        "  model.eval()\n",
        "  for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "    valid_length = valid_length\n",
        "    label = label.long().to(device)\n",
        "\n",
        "    out = model(token_ids, valid_length, segment_ids)\n",
        "\n",
        "    test_eval = []\n",
        "    for i in out:\n",
        "      logits = i\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      per = int(np.max(logits)*100)\n",
        "\n",
        "      if np.argmax(logits)==0:\n",
        "        test_eval.append(\"부정\")\n",
        "      elif np.argmax(logits)==1:\n",
        "        test_eval.append(\"긍정\")\n",
        "      elif np.argmax(logits)==2:\n",
        "        test_eval.append(\"중립\")\n",
        "\n",
        "    print(\">> 해당리뷰는 \"+ per + \"% 확률로\" + test_eval[0] + \" 입니다.\")"
      ],
      "metadata": {
        "id": "Z645WkmRJTFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PredictKOBERT(testdata):\n",
        "  Pos = []\n",
        "  Neg = []\n",
        "  Mid = []\n",
        "  Pred = []\n",
        "  tokenizer = get_tokenizer()\n",
        "  tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "  k = len(testdata['comment'])\n",
        "  for i in range(k):\n",
        "    predict_sentence = testdata['comment'][i]\n",
        "    data = [predict_sentence, '0']\n",
        "    dataset_another = [data]\n",
        "    another_test = BERTDataset(dataset_another, 0, 1, tok, max_len, True, False)\n",
        "    test_dataloader = torch.utils.data.DataLoader(another_test,\n",
        "                                                batch_size=batch_size,\n",
        "                                                num_workers=5)\n",
        "    model.eval()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(test_dataloader):\n",
        "      token_ids = token_ids.long().to(device)\n",
        "      segment_ids = segment_ids.long().to(device)\n",
        "\n",
        "      valid_length = valid_length\n",
        "      label = label.long().to(device)\n",
        "\n",
        "      out = model(token_ids, valid_length, segment_ids)\n",
        "    for i in out:\n",
        "      logits = i\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "\n",
        "      if np.argmax(logits)==0:\n",
        "        Pos.append(0)\n",
        "        Pred.append(0)\n",
        "      elif np.argmax(logits)==1:\n",
        "        Neg.append(1)\n",
        "        Pred.append(1)\n",
        "      elif np.argmax(logits)==2:\n",
        "        Mid.append(2)\n",
        "        Pred.append(2)\n",
        "  testdata['Pred'] = Pred\n",
        "  testdata = testdata[['comment','label','Pred']]\n",
        "  k = len(testdata['comment'])\n",
        "  testdata.to_excel('/content/테스트_리뷰_150개_predBERT_1011(3).xlsx')\n",
        "  print(f'이 기기의 긍정 비율은 {int((len(Pos)/k)*100)}입니다')\n",
        "  print(f'이 기기의 부정 비율은 {int((len(Neg)/k)*100)}입니다')\n",
        "  print(f'이 기기의 중립 비율은 {int((len(Mid)/k)*100)}입니다')\n",
        "  "
      ],
      "metadata": {
        "id": "tjkVpjsyK-DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "myfile = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "id": "WbQ5ZJ5-PFUn",
        "outputId": "20f378d0-a2f8-4308-edff-d48f411b6365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22aefa0b-6965-453c-9b73-4c68e9a3c572\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22aefa0b-6965-453c-9b73-4c68e9a3c572\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = pd.read_excel('/content/테스트_리뷰_150개.xlsx') \n",
        "test_set = test_set[['label','comment']]\n",
        "test_set = test_set.dropna()\n",
        "test_set = test_set.drop_duplicates(['comment'])\n",
        "test_set.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1KjWJJWRPI1z",
        "outputId": "a3b03118-72a8-4640-a74f-b6fa65a7f200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                            comment\n",
              "0      1          오~ 확실히 개인적인 취향으로 B&O가 제일 예쁘네요 ㅋㅋ 맘에 쏙 들어요\n",
              "1      0  쫒겨나기 딱이고 이동성 최악이고 민폐라는 이미지를 각인시키는 1등공신스피커네요 이런...\n",
              "2      0  제품 강력 비추합니다. 개인적으로 보스를 좋아해서 휴대용 스피커, 이어셋, 헤드셋을...\n",
              "3      1  사운드스틱4 만족스럽게 쓰고 있습니다 ㅋㅋ 모니터 양 옆에 두고 쓰기엔 참 좋더라구...\n",
              "4      2  블루투스가 없는 치명적인 단점이 있지만 아이폰이나 아이패드 있으면 에어플레이로 블루..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea2fc297-147a-40c7-832b-7a0d92456861\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>오~ 확실히 개인적인 취향으로 B&amp;O가 제일 예쁘네요 ㅋㅋ 맘에 쏙 들어요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>쫒겨나기 딱이고 이동성 최악이고 민폐라는 이미지를 각인시키는 1등공신스피커네요 이런...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>제품 강력 비추합니다. 개인적으로 보스를 좋아해서 휴대용 스피커, 이어셋, 헤드셋을...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>사운드스틱4 만족스럽게 쓰고 있습니다 ㅋㅋ 모니터 양 옆에 두고 쓰기엔 참 좋더라구...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>블루투스가 없는 치명적인 단점이 있지만 아이폰이나 아이패드 있으면 에어플레이로 블루...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea2fc297-147a-40c7-832b-7a0d92456861')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea2fc297-147a-40c7-832b-7a0d92456861 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea2fc297-147a-40c7-832b-7a0d92456861');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PredictKOBERT(test_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tonw6a5YPVjS",
        "outputId": "e867f894-729e-4989-e498-7375a36fa0a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n",
            "이 기기의 긍정 비율은 29입니다\n",
            "이 기기의 부정 비율은 44입니다\n",
            "이 기기의 중립 비율은 26입니다\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YMl_0o3EFsjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = pd.read_excel('/content/테스트_리뷰_150개_predBERT_1011(3).xlsx') \n",
        "testdata = testdata.dropna()\n",
        "testdata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W3FsAyGpFdST",
        "outputId": "d396b947-2a62-476b-8397-9b927e59b117"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                            comment  label  Pred\n",
              "0           0          오~ 확실히 개인적인 취향으로 B&O가 제일 예쁘네요 ㅋㅋ 맘에 쏙 들어요      1     1\n",
              "1           1  쫒겨나기 딱이고 이동성 최악이고 민폐라는 이미지를 각인시키는 1등공신스피커네요 이런...      0     0\n",
              "2           2  제품 강력 비추합니다. 개인적으로 보스를 좋아해서 휴대용 스피커, 이어셋, 헤드셋을...      0     0\n",
              "3           3  사운드스틱4 만족스럽게 쓰고 있습니다 ㅋㅋ 모니터 양 옆에 두고 쓰기엔 참 좋더라구...      1     1\n",
              "4           4  블루투스가 없는 치명적인 단점이 있지만 아이폰이나 아이패드 있으면 에어플레이로 블루...      2     1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30a82dd7-fd56-4405-b042-e3bb6ccb18e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "      <th>Pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>오~ 확실히 개인적인 취향으로 B&amp;O가 제일 예쁘네요 ㅋㅋ 맘에 쏙 들어요</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>쫒겨나기 딱이고 이동성 최악이고 민폐라는 이미지를 각인시키는 1등공신스피커네요 이런...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>제품 강력 비추합니다. 개인적으로 보스를 좋아해서 휴대용 스피커, 이어셋, 헤드셋을...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>사운드스틱4 만족스럽게 쓰고 있습니다 ㅋㅋ 모니터 양 옆에 두고 쓰기엔 참 좋더라구...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>블루투스가 없는 치명적인 단점이 있지만 아이폰이나 아이패드 있으면 에어플레이로 블루...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30a82dd7-fd56-4405-b042-e3bb6ccb18e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30a82dd7-fd56-4405-b042-e3bb6ccb18e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30a82dd7-fd56-4405-b042-e3bb6ccb18e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install JPype1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_S_8FJ_lHpge",
        "outputId": "bec4ccea-8836-4520-b4be-d828721e8a81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEedTmRpQsud",
        "outputId": "eccddee9-5880-431d-db3c-330459e968bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zUeT11YcUOmd",
        "outputId": "eaac5469-0202-4482-fdd8-f490307278ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/haven-jeon/PyKoSpacing.git\n",
            "  Cloning https://github.com/haven-jeon/PyKoSpacing.git to /tmp/pip-req-build-v3u6ll5f\n",
            "  Running command git clone -q https://github.com/haven-jeon/PyKoSpacing.git /tmp/pip-req-build-v3u6ll5f\n",
            "Requirement already satisfied: tensorflow==2.7.2 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.5) (2.7.2+zzzcolab20220516114640)\n",
            "Requirement already satisfied: h5py==3.1.0 in /usr/local/lib/python3.7/dist-packages (from pykospacing==0.5) (3.1.0)\n",
            "Collecting argparse>=1.4.0\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py==3.1.0->pykospacing==0.5) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.49.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.14.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (2.8.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (2.7.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (2.0.7)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (0.27.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.7.2->pykospacing==0.5) (3.3.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (5.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.2->pykospacing==0.5) (3.2.1)\n",
            "Installing collected packages: argparse\n",
            "Successfully installed argparse-1.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Okt\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "kkma = Kkma()\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "RvroGdrcT_g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "ABprREd_c3gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Keyword(label_):\n",
        "  x = len(testdata['Pred'])\n",
        "  word = []\n",
        "  review_lst=[]\n",
        "  for i in range(x):\n",
        "    if testdata['Pred'][i]==label_:\n",
        "      new_sentence = testdata['comment'][i]\n",
        "      new_sentence = okt.pos(new_sentence, stem = True)\n",
        "      y = len(new_sentence)\n",
        "      for i in range(y):\n",
        "        if new_sentence[i][1]== 'Noun':\n",
        "          p = len(new_sentence[i][0])\n",
        "          if p > 1:\n",
        "            word.append(new_sentence[i][0])\n",
        "  count_noun = Counter(word)\n",
        "  max_num = count_noun.most_common(n=10)\n",
        "  print(max_num)"
      ],
      "metadata": {
        "id": "J-g20dClQvld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Keyword(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynmx-NSnXRTP",
        "outputId": "0e38c11d-d079-4ed5-e8a7-7f13bbd0f7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('정말', 18), ('사용', 15), ('제품', 9), ('노트북', 8), ('가성', 7), ('배터리', 7), ('정도', 7), ('휴대', 6), ('가격', 6), ('생각', 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt.pos('가성비')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdTH0bEXXUNt",
        "outputId": "a161856b-85d0-40fe-abe4-6ee88b9891c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('가성', 'Noun'), ('비', 'Noun')]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentence = '제품 강력 비추합니다. 개인적으로 보스를 좋아해서 휴대용 스피커, 이어셋, 헤드셋을 여러개 써봤는데 항상 내구성이 떨어집니다. 그리고 고장시 수리가 안됩니다. 서비스 센터에서 항상 고칠 수 없다고 하네요. 기술이 없어서가 아니라 보증기간이 끝나고 나면 고쳐주지룰 않아요. '\n",
        "new_sentence = okt.pos(new_sentence, stem = True)\n",
        "y = len(new_sentence)\n",
        "word = []\n",
        "for i in range(y):\n",
        "      if new_sentence[i][1]== 'Noun':\n",
        "        word.append(new_sentence[i][0])"
      ],
      "metadata": {
        "id": "gqrk30hAary0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QichExiia80M",
        "outputId": "bd4c191a-04ac-45a6-e986-4eca32bf4c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['제품',\n",
              " '강력',\n",
              " '개인',\n",
              " '보스',\n",
              " '휴대',\n",
              " '용',\n",
              " '스피커',\n",
              " '셋',\n",
              " '헤드셋',\n",
              " '개',\n",
              " '항상',\n",
              " '구성',\n",
              " '장시',\n",
              " '수리',\n",
              " '서비스',\n",
              " '센터',\n",
              " '항상',\n",
              " '수',\n",
              " '기술',\n",
              " '어서',\n",
              " '보증',\n",
              " '기간',\n",
              " '룰']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lovit/customized_konlpy.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0JBiajcbCgR",
        "outputId": "bfa6919c-8f71-4d55-f76d-113f067131c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'customized_konlpy' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install customized_konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pt4NUPvEeJuh",
        "outputId": "de63227e-3939-421d-e863-39df803edf0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: customized_konlpy in /usr/local/lib/python3.7/dist-packages (0.0.64)\n",
            "Requirement already satisfied: Jpype1>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from customized_konlpy) (1.4.0)\n",
            "Requirement already satisfied: konlpy>=0.4.4 in /usr/local/lib/python3.7/dist-packages (from customized_konlpy) (0.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from Jpype1>=0.6.1->customized_konlpy) (4.1.1)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy>=0.4.4->customized_konlpy) (4.9.1)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy>=0.4.4->customized_konlpy) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ckonlpy.tag import Twitter\n",
        "twitter = Twitter()\n",
        "twitter.template_tagger.templates"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9HgvqvYeK1O",
        "outputId": "3247172b-77d0-44bc-824c-db1f4a260d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/konlpy/tag/_okt.py:17: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
            "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Adjective',),\n",
              " ('Adverb',),\n",
              " ('Conjunction',),\n",
              " ('Exclamation',),\n",
              " ('KoreanParticle',),\n",
              " ('Noun',),\n",
              " ('Verb',),\n",
              " ('Noun', 'Noun'),\n",
              " ('Noun', 'Josa'),\n",
              " ('Noun', 'Adjective'),\n",
              " ('Noun', 'Verb'),\n",
              " ('Modifier', 'Noun'),\n",
              " ('Noun', 'Noun', 'Adjective'),\n",
              " ('Noun', 'Noun', 'Josa'),\n",
              " ('Noun', 'Noun', 'Verb'),\n",
              " ('Modifier', 'Noun', 'Josa'),\n",
              " ('Josa',)]"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.template_tagger.add_a_template(('review',))"
      ],
      "metadata": {
        "id": "cc2ph8TNeiDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import os\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "s93_yh5ye4nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk\n",
        "!pip3 install konlpy\n",
        "!pip3 install JPype1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ1N1zXwgs0o",
        "outputId": "c84c08b0-6360-4831-be5e-2f93e8fec375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "openjdk-8-jdk is already the newest version (8u342-b07-0ubuntu1~18.04).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.4.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: JPype1 in /usr/local/lib/python3.7/dist-packages (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import konlpy\n",
        "konlpy.data.path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhCgG-hygvDO",
        "outputId": "3da00bf4-3a4f-476c-c418-e78d2c823b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/root/konlpy_data',\n",
              " '/usr/share/konlpy_data',\n",
              " '/usr/local/share/konlpy_data',\n",
              " '/usr/lib/konlpy_data',\n",
              " '/usr/local/lib/konlpy_data',\n",
              " '/usr/local/lib/python3.7/dist-packages/konlpy/data']"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# automake 설치\n",
        "os.chdir('/tmp')\n",
        "!curl -LO http://ftpmirror.gnu.org/automake/automake-1.11.tar.gz\n",
        "!tar -zxvf automake-1.11.tar.gz\n",
        "os.chdir('/tmp/automake-1.11')\n",
        "!./configure\n",
        "!make\n",
        "!make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4mbgaVggxpY",
        "outputId": "4c3eb1aa-c464-4fa5-9f90-4d3e93d94e5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 1339k  100 1339k    0     0   688k      0  0:00:01  0:00:01 --:--:--  688k\n",
            "automake-1.11/\n",
            "automake-1.11/THANKS\n",
            "automake-1.11/ChangeLog.03\n",
            "automake-1.11/automake.in\n",
            "automake-1.11/ChangeLog.96\n",
            "automake-1.11/ChangeLog.98\n",
            "automake-1.11/m4/\n",
            "automake-1.11/m4/gcj.m4\n",
            "automake-1.11/m4/missing.m4\n",
            "automake-1.11/m4/runlog.m4\n",
            "automake-1.11/m4/lex.m4\n",
            "automake-1.11/m4/vala.m4\n",
            "automake-1.11/m4/obsol-gt.m4\n",
            "automake-1.11/m4/obsol-lt.m4\n",
            "automake-1.11/m4/minuso.m4\n",
            "automake-1.11/m4/ccstdc.m4\n",
            "automake-1.11/m4/install-sh.m4\n",
            "automake-1.11/m4/upc.m4\n",
            "automake-1.11/m4/sanity.m4\n",
            "automake-1.11/m4/amversion.m4\n",
            "automake-1.11/m4/make.m4\n",
            "automake-1.11/m4/auxdir.m4\n",
            "automake-1.11/m4/options.m4\n",
            "automake-1.11/m4/lispdir.m4\n",
            "automake-1.11/m4/Makefile.am\n",
            "automake-1.11/m4/dirlist\n",
            "automake-1.11/m4/cond.m4\n",
            "automake-1.11/m4/mkdirp.m4\n",
            "automake-1.11/m4/cond-if.m4\n",
            "automake-1.11/m4/as.m4\n",
            "automake-1.11/m4/amversion.in\n",
            "automake-1.11/m4/silent.m4\n",
            "automake-1.11/m4/depout.m4\n",
            "automake-1.11/m4/maintainer.m4\n",
            "automake-1.11/m4/protos.m4\n",
            "automake-1.11/m4/lead-dot.m4\n",
            "automake-1.11/m4/python.m4\n",
            "automake-1.11/m4/strip.m4\n",
            "automake-1.11/m4/tar.m4\n",
            "automake-1.11/m4/header.m4\n",
            "automake-1.11/m4/obsolete.m4\n",
            "automake-1.11/m4/Makefile.in\n",
            "automake-1.11/m4/multi.m4\n",
            "automake-1.11/m4/regex.m4\n",
            "automake-1.11/m4/dmalloc.m4\n",
            "automake-1.11/m4/depend.m4\n",
            "automake-1.11/m4/init.m4\n",
            "automake-1.11/m4/substnot.m4\n",
            "automake-1.11/ChangeLog\n",
            "automake-1.11/tests/\n",
            "automake-1.11/tests/acloca11.test\n",
            "automake-1.11/tests/nobase.test\n",
            "automake-1.11/tests/maken2.test\n",
            "automake-1.11/tests/distname.test\n",
            "automake-1.11/tests/instdir.test\n",
            "automake-1.11/tests/conff.test\n",
            "automake-1.11/tests/bsource.test\n",
            "automake-1.11/tests/silent3.test\n",
            "automake-1.11/tests/depcomp2.test\n",
            "automake-1.11/tests/autohdr4.test\n",
            "automake-1.11/tests/pr307.test\n",
            "automake-1.11/tests/mkinst3.test\n",
            "automake-1.11/tests/parallel-am.test\n",
            "automake-1.11/tests/comment2.test\n",
            "automake-1.11/tests/output2.test\n",
            "automake-1.11/tests/pr87.test\n",
            "automake-1.11/tests/libobj12.test\n",
            "automake-1.11/tests/suffix10.test\n",
            "automake-1.11/tests/parallel-tests8.test\n",
            "automake-1.11/tests/maken3.test\n",
            "automake-1.11/tests/txinfo10.test\n",
            "automake-1.11/tests/instdir-python.test\n",
            "automake-1.11/tests/libobj11.test\n",
            "automake-1.11/tests/txinfo6.test\n",
            "automake-1.11/tests/reqd2.test\n",
            "automake-1.11/tests/comment.test\n",
            "automake-1.11/tests/parallel-tests.am\n",
            "automake-1.11/tests/subst3.test\n",
            "automake-1.11/tests/instman2.test\n",
            "automake-1.11/tests/java2.test\n",
            "automake-1.11/tests/acloca21.test\n",
            "automake-1.11/tests/backsl2.test\n",
            "automake-1.11/tests/tar2.test\n",
            "automake-1.11/tests/txinfo32.test\n",
            "automake-1.11/tests/cond10.test\n",
            "automake-1.11/tests/cygwin32.test\n",
            "automake-1.11/tests/longline.test\n",
            "automake-1.11/tests/subpkg.test\n",
            "automake-1.11/tests/ltlibobjs.test\n",
            "automake-1.11/tests/instdir-lisp.test\n",
            "automake-1.11/tests/instdir-texi.test\n",
            "automake-1.11/tests/python6.test\n",
            "automake-1.11/tests/depdist.test\n",
            "automake-1.11/tests/yaccvpath.test\n",
            "automake-1.11/tests/ansi5.test\n",
            "automake-1.11/tests/aclocal4.test\n",
            "automake-1.11/tests/cond35.test\n",
            "automake-1.11/tests/tar.test\n",
            "automake-1.11/tests/pr401c-p.test\n",
            "automake-1.11/tests/silent2.test\n",
            "automake-1.11/tests/exeext3.test\n",
            "automake-1.11/tests/missing.test\n",
            "automake-1.11/tests/suffix6.test\n",
            "automake-1.11/tests/primary.test\n",
            "automake-1.11/tests/instexec.test\n",
            "automake-1.11/tests/extra.test\n",
            "automake-1.11/tests/comment9.test\n",
            "automake-1.11/tests/empty3.test\n",
            "automake-1.11/tests/pr211.test\n",
            "automake-1.11/tests/nodist3.test\n",
            "automake-1.11/tests/parallel-tests6.test\n",
            "automake-1.11/tests/gnuwarn2.test\n",
            "automake-1.11/tests/insh2.test\n",
            "automake-1.11/tests/depcomp5.test\n",
            "automake-1.11/tests/cond13.test\n",
            "automake-1.11/tests/parallel-tests9.test\n",
            "automake-1.11/tests/libtool.test\n",
            "automake-1.11/tests/auxdir4.test\n",
            "automake-1.11/tests/targetclash.test\n",
            "automake-1.11/tests/check6.test\n",
            "automake-1.11/tests/cond39.test\n",
            "automake-1.11/tests/specflg3.test\n",
            "automake-1.11/tests/gcj4.test\n",
            "automake-1.11/tests/werror.test\n",
            "automake-1.11/tests/depend3.test\n",
            "automake-1.11/tests/acloca12.test\n",
            "automake-1.11/tests/subdir.test\n",
            "automake-1.11/tests/check7.test\n",
            "automake-1.11/tests/yacc5.test\n",
            "automake-1.11/tests/werror2.test\n",
            "automake-1.11/tests/listval.test\n",
            "automake-1.11/tests/libobj2.test\n",
            "automake-1.11/tests/vars3.test\n",
            "automake-1.11/tests/comment7.test\n",
            "automake-1.11/tests/distcom5.test\n",
            "automake-1.11/tests/pluseq4.test\n",
            "automake-1.11/tests/pr224.test\n",
            "automake-1.11/tests/txinfo22.test\n",
            "automake-1.11/tests/txinfo9.test\n",
            "automake-1.11/tests/lex2.test\n",
            "automake-1.11/tests/parallel-tests7.test\n",
            "automake-1.11/tests/check10-p.test\n",
            "automake-1.11/tests/canon5.test\n",
            "automake-1.11/tests/python7.test\n",
            "automake-1.11/tests/confh4.test\n",
            "automake-1.11/tests/pluseq10.test\n",
            "automake-1.11/tests/conflnk3.test\n",
            "automake-1.11/tests/canon4.test\n",
            "automake-1.11/tests/output7.test\n",
            "automake-1.11/tests/link_fc.test\n",
            "automake-1.11/tests/missing6.test\n",
            "automake-1.11/tests/mdate.test\n",
            "automake-1.11/tests/exeext.test\n",
            "automake-1.11/tests/cond30.test\n",
            "automake-1.11/tests/txinfo.test\n",
            "automake-1.11/tests/remake4.test\n",
            "automake-1.11/tests/objc2.test\n",
            "automake-1.11/tests/destdir.test\n",
            "automake-1.11/tests/acoutqnl.test\n",
            "automake-1.11/tests/number.test\n",
            "automake-1.11/tests/library.test\n",
            "automake-1.11/tests/silent7.test\n",
            "automake-1.11/tests/subcond2.test\n",
            "automake-1.11/tests/confh5.test\n",
            "automake-1.11/tests/asm.test\n",
            "automake-1.11/tests/obsolete.test\n",
            "automake-1.11/tests/python12.test\n",
            "automake-1.11/tests/defun.test\n",
            "automake-1.11/tests/subdir5.test\n",
            "automake-1.11/tests/nodef.test\n",
            "automake-1.11/tests/ext2.test\n",
            "automake-1.11/tests/confvar2.test\n",
            "automake-1.11/tests/double.test\n",
            "automake-1.11/tests/clean.test\n",
            "automake-1.11/tests/aclocal5.test\n",
            "automake-1.11/tests/asm3.test\n",
            "automake-1.11/tests/check4-p.test\n",
            "automake-1.11/tests/suffix4.test\n",
            "automake-1.11/tests/subst.test\n",
            "automake-1.11/tests/comment9-p.test\n",
            "automake-1.11/tests/cond7.test\n",
            "automake-1.11/tests/depcomp7.test\n",
            "automake-1.11/tests/upc.test\n",
            "automake-1.11/tests/txinfo4.test\n",
            "automake-1.11/tests/install2.test\n",
            "automake-1.11/tests/instsh.test\n",
            "automake-1.11/tests/silent5.test\n",
            "automake-1.11/tests/seenc.test\n",
            "automake-1.11/tests/compile_f_c_cxx.test\n",
            "automake-1.11/tests/output9.test\n",
            "automake-1.11/tests/syntax.test\n",
            "automake-1.11/tests/comment4.test\n",
            "automake-1.11/tests/ansi4.test\n",
            "automake-1.11/tests/order.test\n",
            "automake-1.11/tests/acloca15.test\n",
            "automake-1.11/tests/check3.test\n",
            "automake-1.11/tests/automake.test\n",
            "automake-1.11/tests/check7-p.test\n",
            "automake-1.11/tests/config.test\n",
            "automake-1.11/tests/condman2.test\n",
            "automake-1.11/tests/pr243.test\n",
            "automake-1.11/tests/fpinst2.test\n",
            "automake-1.11/tests/ansi2.test\n",
            "automake-1.11/tests/fortdep.test\n",
            "automake-1.11/tests/specflg6.test\n",
            "automake-1.11/tests/distcom7.test\n",
            "automake-1.11/tests/libtool9.test\n",
            "automake-1.11/tests/specflg.test\n",
            "automake-1.11/tests/txinfo26.test\n",
            "automake-1.11/tests/license.test\n",
            "automake-1.11/tests/output5.test\n",
            "automake-1.11/tests/sinclude.test\n",
            "automake-1.11/tests/gettext.test\n",
            "automake-1.11/tests/txinfo21.test\n",
            "automake-1.11/tests/pluseq9.test\n",
            "automake-1.11/tests/instfail.test\n",
            "automake-1.11/tests/subdir2.test\n",
            "automake-1.11/tests/percent.test\n",
            "automake-1.11/tests/libtool5.test\n",
            "automake-1.11/tests/notrans.test\n",
            "automake-1.11/tests/pluseq.test\n",
            "automake-1.11/tests/flavor.test\n",
            "automake-1.11/tests/distdir.test\n",
            "automake-1.11/tests/mkinstall.test\n",
            "automake-1.11/tests/symlink.test\n",
            "automake-1.11/tests/subst4.test\n",
            "automake-1.11/tests/maken.test\n",
            "automake-1.11/tests/ansi3b.test\n",
            "automake-1.11/tests/automake.in\n",
            "automake-1.11/tests/canon3.test\n",
            "automake-1.11/tests/txinfo18.test\n",
            "automake-1.11/tests/pr287.test\n",
            "automake-1.11/tests/ansi6.test\n",
            "automake-1.11/tests/include.test\n",
            "automake-1.11/tests/copy.test\n",
            "automake-1.11/tests/cond.test\n",
            "automake-1.11/tests/depend2.test\n",
            "automake-1.11/tests/depcomp3.test\n",
            "automake-1.11/tests/distcom4.test\n",
            "automake-1.11/tests/symlink3.test\n",
            "automake-1.11/tests/yacc2.test\n",
            "automake-1.11/tests/man.test\n",
            "automake-1.11/tests/txinfo17.test\n",
            "automake-1.11/tests/autohdr.test\n",
            "automake-1.11/tests/cond23.test\n",
            "automake-1.11/tests/vpath.test\n",
            "automake-1.11/tests/version.test\n",
            "automake-1.11/tests/nogzip2.test\n",
            "automake-1.11/tests/fo.test\n",
            "automake-1.11/tests/acsubst2.test\n",
            "automake-1.11/tests/yacc4.test\n",
            "automake-1.11/tests/extra3.test\n",
            "automake-1.11/tests/aclibobj.test\n",
            "automake-1.11/tests/acloca10.test\n",
            "automake-1.11/tests/ccnoco2.test\n",
            "automake-1.11/tests/alloca.test\n",
            "automake-1.11/tests/lisp6.test\n",
            "automake-1.11/tests/python3.test\n",
            "automake-1.11/tests/colon6.test\n",
            "automake-1.11/tests/makej.test\n",
            "automake-1.11/tests/colon5.test\n",
            "automake-1.11/tests/specflg2.test\n",
            "automake-1.11/tests/vala1.test\n",
            "automake-1.11/tests/vtexi2.test\n",
            "automake-1.11/tests/gcj2.test\n",
            "automake-1.11/tests/output3.test\n",
            "automake-1.11/tests/cond26.test\n",
            "automake-1.11/tests/ltinstloc.test\n",
            "automake-1.11/tests/interp2.test\n",
            "automake-1.11/tests/color.test\n",
            "automake-1.11/tests/lex4.test\n",
            "automake-1.11/tests/cond38.test\n",
            "automake-1.11/tests/hosts.test\n",
            "automake-1.11/tests/lisp5.test\n",
            "automake-1.11/tests/mkinst2.test\n",
            "automake-1.11/tests/cond43.test\n",
            "automake-1.11/tests/man2.test\n",
            "automake-1.11/tests/depend6.test\n",
            "automake-1.11/tests/transform.test\n",
            "automake-1.11/tests/comment5.test\n",
            "automake-1.11/tests/cond34.test\n",
            "automake-1.11/tests/cond4.test\n",
            "automake-1.11/tests/vala.test\n",
            "automake-1.11/tests/srcsub2.test\n",
            "automake-1.11/tests/acloca19.test\n",
            "automake-1.11/tests/cond36.test\n",
            "automake-1.11/tests/backsl.test\n",
            "automake-1.11/tests/colneq2.test\n",
            "automake-1.11/tests/pr2.test\n",
            "automake-1.11/tests/cond17.test\n",
            "automake-1.11/tests/fn99subdir.test\n",
            "automake-1.11/tests/lisp4.test\n",
            "automake-1.11/tests/cond16.test\n",
            "automake-1.11/tests/gettext2.test\n",
            "automake-1.11/tests/colon.test\n",
            "automake-1.11/tests/acloca16.test\n",
            "automake-1.11/tests/check2.test\n",
            "automake-1.11/tests/cond22.test\n",
            "automake-1.11/tests/proginst.test\n",
            "automake-1.11/tests/parallel-tests5.test\n",
            "automake-1.11/tests/version3.test\n",
            "automake-1.11/tests/fn99.test\n",
            "automake-1.11/tests/man3.test\n",
            "automake-1.11/tests/libtool3.test\n",
            "automake-1.11/tests/nostdinc.test\n",
            "automake-1.11/tests/confdeps.test\n",
            "automake-1.11/tests/cond32.test\n",
            "automake-1.11/tests/remake6.test\n",
            "automake-1.11/tests/empty4.test\n",
            "automake-1.11/tests/cond20.test\n",
            "automake-1.11/tests/insthook.test\n",
            "automake-1.11/tests/gcj.test\n",
            "automake-1.11/tests/extra8.test\n",
            "automake-1.11/tests/parallel-tests3.test\n",
            "automake-1.11/tests/instman.test\n",
            "automake-1.11/tests/subobj10.test\n",
            "automake-1.11/tests/lzma.test\n",
            "automake-1.11/tests/alloca2.test\n",
            "automake-1.11/tests/version4.test\n",
            "automake-1.11/tests/instdir-java.test\n",
            "automake-1.11/tests/cxxansi.test\n",
            "automake-1.11/tests/noinst.test\n",
            "automake-1.11/tests/condlib.test\n",
            "automake-1.11/tests/subobj.test\n",
            "automake-1.11/tests/link_f_only.test\n",
            "automake-1.11/tests/stdlib.test\n",
            "automake-1.11/tests/upc3.test\n",
            "automake-1.11/tests/transform2.test\n",
            "automake-1.11/tests/location.test\n",
            "automake-1.11/tests/dirforbid.test\n",
            "automake-1.11/tests/installdir.test\n",
            "automake-1.11/tests/libtool7.test\n",
            "automake-1.11/tests/subobj9.test\n",
            "automake-1.11/tests/fort1.test\n",
            "automake-1.11/tests/fort4.test\n",
            "automake-1.11/tests/yacc7.test\n",
            "automake-1.11/tests/gnumake.test\n",
            "automake-1.11/tests/suffix2.test\n",
            "automake-1.11/tests/help.test\n",
            "automake-1.11/tests/fort5.test\n",
            "automake-1.11/tests/condinc2.test\n",
            "automake-1.11/tests/pr300-ltlib.test\n",
            "automake-1.11/tests/ldadd.test\n",
            "automake-1.11/tests/nolink.test\n",
            "automake-1.11/tests/instmany-python.test\n",
            "automake-1.11/tests/cond42.test\n",
            "automake-1.11/tests/backsl4.test\n",
            "automake-1.11/tests/output11.test\n",
            "automake-1.11/tests/java3.test\n",
            "automake-1.11/tests/pr300-lib.test\n",
            "automake-1.11/tests/mmode.test\n",
            "automake-1.11/tests/spell.test\n",
            "automake-1.11/tests/empty.test\n",
            "automake-1.11/tests/cxxcpp.test\n",
            "automake-1.11/tests/pr229.test\n",
            "automake-1.11/tests/outdir.test\n",
            "automake-1.11/tests/lisp2.test\n",
            "automake-1.11/tests/txinfo24.test\n",
            "automake-1.11/tests/tar3.test\n",
            "automake-1.11/tests/recurs.test\n",
            "automake-1.11/tests/ansi7.test\n",
            "automake-1.11/tests/check11-p.test\n",
            "automake-1.11/tests/colon7.test\n",
            "automake-1.11/tests/confsub.test\n",
            "automake-1.11/tests/check8.test\n",
            "automake-1.11/tests/pluseq6.test\n",
            "automake-1.11/tests/cxx.test\n",
            "automake-1.11/tests/libtool6.test\n",
            "automake-1.11/tests/check6-p.test\n",
            "automake-1.11/tests/pr401c.test\n",
            "automake-1.11/tests/txinfo13.test\n",
            "automake-1.11/tests/silent.test\n",
            "automake-1.11/tests/makevars.test\n",
            "automake-1.11/tests/space.test\n",
            "automake-1.11/tests/sanity.test\n",
            "automake-1.11/tests/ctarget1.test\n",
            "automake-1.11/tests/nodist.test\n",
            "automake-1.11/tests/nobase-libtool.test\n",
            "automake-1.11/tests/txinfo16.test\n",
            "automake-1.11/tests/xsource.test\n",
            "automake-1.11/tests/parallel-am2.test\n",
            "automake-1.11/tests/python5.test\n",
            "automake-1.11/tests/dup2.test\n",
            "automake-1.11/tests/colon4.test\n",
            "automake-1.11/tests/dejagnu7.test\n",
            "automake-1.11/tests/interp.test\n",
            "automake-1.11/tests/libtoo10.test\n",
            "automake-1.11/tests/multlib.test\n",
            "automake-1.11/tests/vars.test\n",
            "automake-1.11/tests/python2.test\n",
            "automake-1.11/tests/nobase-python.test\n",
            "automake-1.11/tests/cond24.test\n",
            "automake-1.11/tests/cond28.test\n",
            "automake-1.11/tests/missing2.test\n",
            "automake-1.11/tests/mdate3.test\n",
            "automake-1.11/tests/ansi3.test\n",
            "automake-1.11/tests/condman.test\n",
            "automake-1.11/tests/pr401b-p.test\n",
            "automake-1.11/tests/python.test\n",
            "automake-1.11/tests/cond6.test\n",
            "automake-1.11/tests/ar.test\n",
            "automake-1.11/tests/all.test\n",
            "automake-1.11/tests/pr279-2.test\n",
            "automake-1.11/tests/auxdir3.test\n",
            "automake-1.11/tests/missing3.test\n",
            "automake-1.11/tests/longlin2.test\n",
            "automake-1.11/tests/dejagnu.test\n",
            "automake-1.11/tests/else.test\n",
            "automake-1.11/tests/info.test\n",
            "automake-1.11/tests/instdir-ltlib.test\n",
            "automake-1.11/tests/percent2.test\n",
            "automake-1.11/tests/cond5.test\n",
            "automake-1.11/tests/libobj10.test\n",
            "automake-1.11/tests/commen11.test\n",
            "automake-1.11/tests/colneq.test\n",
            "automake-1.11/tests/ansi9.test\n",
            "automake-1.11/tests/acloca13.test\n",
            "automake-1.11/tests/unused.test\n",
            "automake-1.11/tests/parallel-tests4.test\n",
            "automake-1.11/tests/cxx2.test\n",
            "automake-1.11/tests/postproc.test\n",
            "automake-1.11/tests/dejagnu3.test\n",
            "automake-1.11/tests/link_fcxx.test\n",
            "automake-1.11/tests/specflg10.test\n",
            "automake-1.11/tests/ltdeps.test\n",
            "automake-1.11/tests/libtoo11.test\n",
            "automake-1.11/tests/cond9.test\n",
            "automake-1.11/tests/output4.test\n",
            "automake-1.11/tests/txinfo23.test\n",
            "automake-1.11/tests/yacc3.test\n",
            "automake-1.11/tests/link_fccxx.test\n",
            "automake-1.11/tests/link_f90_only.test\n",
            "automake-1.11/tests/pr300-prog.test\n",
            "automake-1.11/tests/vala5.test\n",
            "automake-1.11/tests/check11.test\n",
            "automake-1.11/tests/libobj3.test\n",
            "automake-1.11/tests/exeext4-p.test\n",
            "automake-1.11/tests/mdate5.test\n",
            "automake-1.11/tests/acoutbs.test\n",
            "automake-1.11/tests/acsilent.test\n",
            "automake-1.11/tests/empty2.test\n",
            "automake-1.11/tests/dirlist2.test\n",
            "automake-1.11/tests/license2.test\n",
            "automake-1.11/tests/substtarg.test\n",
            "automake-1.11/tests/instdat2.test\n",
            "automake-1.11/tests/specflg7.test\n",
            "automake-1.11/tests/pr204.test\n",
            "automake-1.11/tests/acsubst.test\n",
            "automake-1.11/tests/compile_f90_c_cxx.test\n",
            "automake-1.11/tests/req.test\n",
            "automake-1.11/tests/libtool2.test\n",
            "automake-1.11/tests/compile2.test\n",
            "automake-1.11/tests/distcom2.test\n",
            "automake-1.11/tests/check9.test\n",
            "automake-1.11/tests/missing5.test\n",
            "automake-1.11/tests/library2.test\n",
            "automake-1.11/tests/pr72.test\n",
            "automake-1.11/tests/vala2.test\n",
            "automake-1.11/tests/output-order.test\n",
            "automake-1.11/tests/output.test\n",
            "automake-1.11/tests/cond27.test\n",
            "automake-1.11/tests/ChangeLog-old\n",
            "automake-1.11/tests/acloca17.test\n",
            "automake-1.11/tests/python9.test\n",
            "automake-1.11/tests/cond37.test\n",
            "automake-1.11/tests/cond11.test\n",
            "automake-1.11/tests/whoami.test\n",
            "automake-1.11/tests/txinfo25.test\n",
            "automake-1.11/tests/txinfo2.test\n",
            "automake-1.11/tests/yacc.test\n",
            "automake-1.11/tests/suffix9.test\n",
            "automake-1.11/tests/check10.test\n",
            "automake-1.11/tests/dollarvar2.test\n",
            "automake-1.11/tests/subpkg2.test\n",
            "automake-1.11/tests/pr401.test\n",
            "automake-1.11/tests/maken4-p.test\n",
            "automake-1.11/tests/depcomp4.test\n",
            "automake-1.11/tests/txinfo19.test\n",
            "automake-1.11/tests/extra4.test\n",
            "automake-1.11/tests/suffix13.test\n",
            "automake-1.11/tests/txinfo8.test\n",
            "automake-1.11/tests/upc2.test\n",
            "automake-1.11/tests/warnopts.test\n",
            "automake-1.11/tests/depend.test\n",
            "automake-1.11/tests/spell3.test\n",
            "automake-1.11/tests/fpinstall.test\n",
            "automake-1.11/tests/subdir3.test\n",
            "automake-1.11/tests/clean2.test\n",
            "automake-1.11/tests/aclocal.test\n",
            "automake-1.11/tests/gnuwarn.test\n",
            "automake-1.11/tests/instdir2.test\n",
            "automake-1.11/tests/remake5.test\n",
            "automake-1.11/tests/txinfo30.test\n",
            "automake-1.11/tests/spell2.test\n",
            "automake-1.11/tests/overrid.test\n",
            "automake-1.11/tests/ammissing.test\n",
            "automake-1.11/tests/auxdir2.test\n",
            "automake-1.11/tests/subobj6.test\n",
            "automake-1.11/tests/cond18.test\n",
            "automake-1.11/tests/depend5.test\n",
            "automake-1.11/tests/cond29.test\n",
            "automake-1.11/tests/pluseq3.test\n",
            "automake-1.11/tests/compile.test\n",
            "automake-1.11/tests/txinfo7.test\n",
            "automake-1.11/tests/header.test\n",
            "automake-1.11/tests/remake7.test\n",
            "automake-1.11/tests/silent6.test\n",
            "automake-1.11/tests/vala4.test\n",
            "automake-1.11/tests/conflnk4.test\n",
            "automake-1.11/tests/subdir9.test\n",
            "automake-1.11/tests/primary3.test\n",
            "automake-1.11/tests/Makefile.am\n",
            "automake-1.11/tests/depend4.test\n",
            "automake-1.11/tests/output8.test\n",
            "automake-1.11/tests/txinfo5.test\n",
            "automake-1.11/tests/check3-p.test\n",
            "automake-1.11/tests/nodef2.test\n",
            "automake-1.11/tests/instfail-info.test\n",
            "automake-1.11/tests/autohdr3.test\n",
            "automake-1.11/tests/version6.test\n",
            "automake-1.11/tests/cxxo.test\n",
            "automake-1.11/tests/txinfo3.test\n",
            "automake-1.11/tests/pr220.test\n",
            "automake-1.11/tests/link_c_cxx.test\n",
            "automake-1.11/tests/cond19.test\n",
            "automake-1.11/tests/srcsub.test\n",
            "automake-1.11/tests/acloca20.test\n",
            "automake-1.11/tests/aclocal3.test\n",
            "automake-1.11/tests/yaccpp.test\n",
            "automake-1.11/tests/nodist2.test\n",
            "automake-1.11/tests/output13.test\n",
            "automake-1.11/tests/stdlib2.test\n",
            "automake-1.11/tests/dash.test\n",
            "automake-1.11/tests/txinfo33.test\n",
            "automake-1.11/tests/recurs2.test\n",
            "automake-1.11/tests/instspc.test\n",
            "automake-1.11/tests/README\n",
            "automake-1.11/tests/subpkg3.test\n",
            "automake-1.11/tests/strip.test\n",
            "automake-1.11/tests/ansi.test\n",
            "automake-1.11/tests/dejagnu-p.test\n",
            "automake-1.11/tests/confvar.test\n",
            "automake-1.11/tests/suffix12.test\n",
            "automake-1.11/tests/instsh2.test\n",
            "automake-1.11/tests/xz.test\n",
            "automake-1.11/tests/lex5.test\n",
            "automake-1.11/tests/acoutnoq.test\n",
            "automake-1.11/tests/f90only.test\n",
            "automake-1.11/tests/cond25.test\n",
            "automake-1.11/tests/maken4.test\n",
            "automake-1.11/tests/substre2.test\n",
            "automake-1.11/tests/lisp3.test\n",
            "automake-1.11/tests/python10.test\n",
            "automake-1.11/tests/condinc.test\n",
            "automake-1.11/tests/comment3.test\n",
            "automake-1.11/tests/aclocal8.test\n",
            "automake-1.11/tests/confincl.test\n",
            "automake-1.11/tests/libobj5.test\n",
            "automake-1.11/tests/txinfo27.test\n",
            "automake-1.11/tests/mdate4.test\n",
            "automake-1.11/tests/instdat.test\n",
            "automake-1.11/tests/txinfo31.test\n",
            "automake-1.11/tests/vartar.test\n",
            "automake-1.11/tests/nogzip.test\n",
            "automake-1.11/tests/fonly.test\n",
            "automake-1.11/tests/man5.test\n",
            "automake-1.11/tests/extra7.test\n",
            "automake-1.11/tests/colon3.test\n",
            "automake-1.11/tests/dejagnu6.test\n",
            "automake-1.11/tests/amassign.test\n",
            "automake-1.11/tests/ltconv.test\n",
            "automake-1.11/tests/check-p.test\n",
            "automake-1.11/tests/fort2.test\n",
            "automake-1.11/tests/check2-p.test\n",
            "automake-1.11/tests/symlink2.test\n",
            "automake-1.11/tests/instdir-prog.test\n",
            "automake-1.11/tests/confh.test\n",
            "automake-1.11/tests/objc.test\n",
            "automake-1.11/tests/rulepat.test\n",
            "automake-1.11/tests/mclean.test\n",
            "automake-1.11/tests/pluseq8.test\n",
            "automake-1.11/tests/subdir8.test\n",
            "automake-1.11/tests/init.test\n",
            "automake-1.11/tests/check8-p.test\n",
            "automake-1.11/tests/amopt.test\n",
            "automake-1.11/tests/suffix.test\n",
            "automake-1.11/tests/depcomp6.test\n",
            "automake-1.11/tests/flibs.test\n",
            "automake-1.11/tests/missing4.test\n",
            "automake-1.11/tests/yacc8.test\n",
            "automake-1.11/tests/specflg8.test\n",
            "automake-1.11/tests/subcond.test\n",
            "automake-1.11/tests/cond3.test\n",
            "automake-1.11/tests/txinfo20.test\n",
            "automake-1.11/tests/badprog.test\n",
            "automake-1.11/tests/auxdir.test\n",
            "automake-1.11/tests/implicit.test\n",
            "automake-1.11/tests/gnits.test\n",
            "automake-1.11/tests/check.test\n",
            "automake-1.11/tests/acloca14.test\n",
            "automake-1.11/tests/canon-name.test\n",
            "automake-1.11/tests/discover.test\n",
            "automake-1.11/tests/aclocal6.test\n",
            "automake-1.11/tests/conff2.test\n",
            "automake-1.11/tests/output6.test\n",
            "automake-1.11/tests/gcj3.test\n",
            "automake-1.11/tests/instfail-java.test\n",
            "automake-1.11/tests/cxxlibobj.test\n",
            "automake-1.11/tests/vala3.test\n",
            "automake-1.11/tests/txinfo29.test\n",
            "automake-1.11/tests/parallel-am3.test\n",
            "automake-1.11/tests/block.test\n",
            "automake-1.11/tests/parse.test\n",
            "automake-1.11/tests/conflnk.test\n",
            "automake-1.11/tests/lex.test\n",
            "automake-1.11/tests/dejagnu5.test\n",
            "automake-1.11/tests/depcomp.test\n",
            "automake-1.11/tests/fnoc.test\n",
            "automake-1.11/tests/subdir7.test\n",
            "automake-1.11/tests/version8.test\n",
            "automake-1.11/tests/dirlist.test\n",
            "automake-1.11/tests/dejagnu2.test\n",
            "automake-1.11/tests/cond21.test\n",
            "automake-1.11/tests/exeext4.test\n",
            "automake-1.11/tests/primary2.test\n",
            "automake-1.11/tests/exdir3.test\n",
            "automake-1.11/tests/ltcond2.test\n",
            "automake-1.11/tests/output10.test\n",
            "automake-1.11/tests/subobj4.test\n",
            "automake-1.11/tests/txinfo28.test\n",
            "automake-1.11/tests/library3.test\n",
            "automake-1.11/tests/nodep.test\n",
            "automake-1.11/tests/comment8.test\n",
            "automake-1.11/tests/hfs.test\n",
            "automake-1.11/tests/autohdr2.test\n",
            "automake-1.11/tests/color-p.test\n",
            "automake-1.11/tests/acloca18.test\n",
            "automake-1.11/tests/parallel-tests.test\n",
            "automake-1.11/tests/man4.test\n",
            "automake-1.11/tests/remake3.test\n",
            "automake-1.11/tests/ldflags.test\n",
            "automake-1.11/tests/cond14.test\n",
            "automake-1.11/tests/depacl2.test\n",
            "automake-1.11/tests/check9-p.test\n",
            "automake-1.11/tests/ltorder.test\n",
            "automake-1.11/tests/mmodely.test\n",
            "automake-1.11/tests/include2.test\n",
            "automake-1.11/tests/spy.test\n",
            "automake-1.11/tests/commen10.test\n",
            "automake-1.11/tests/extra5.test\n",
            "automake-1.11/tests/subobj3.test\n",
            "automake-1.11/tests/comment6.test\n",
            "automake-1.11/tests/substref.test\n",
            "automake-1.11/tests/make.test\n",
            "automake-1.11/tests/asm2.test\n",
            "automake-1.11/tests/check5-p.test\n",
            "automake-1.11/tests/instmany-mans.test\n",
            "automake-1.11/tests/gettext3.test\n",
            "automake-1.11/tests/subobj8.test\n",
            "automake-1.11/tests/exdir2.test\n",
            "automake-1.11/tests/condd.test\n",
            "automake-1.11/tests/suffix5.test\n",
            "automake-1.11/tests/parallel-tests2.test\n",
            "automake-1.11/tests/subpkg4.test\n",
            "automake-1.11/tests/lisp7.test\n",
            "automake-1.11/tests/exsource.test\n",
            "automake-1.11/tests/extra6.test\n",
            "automake-1.11/tests/javaprim.test\n",
            "automake-1.11/tests/ar2.test\n",
            "automake-1.11/tests/canon2.test\n",
            "automake-1.11/tests/silent4.test\n",
            "automake-1.11/tests/libobj4.test\n",
            "automake-1.11/tests/gen-parallel-tests\n",
            "automake-1.11/tests/remake.test\n",
            "automake-1.11/tests/acoutpt.test\n",
            "automake-1.11/tests/distcom3.test\n",
            "automake-1.11/tests/python11.test\n",
            "automake-1.11/tests/ansi8.test\n",
            "automake-1.11/tests/gnits2.test\n",
            "automake-1.11/tests/subobjname.test\n",
            "automake-1.11/tests/badline.test\n",
            "automake-1.11/tests/subcond3.test\n",
            "automake-1.11/tests/ltcond.test\n",
            "automake-1.11/tests/ltlibsrc.test\n",
            "automake-1.11/tests/regex.test\n",
            "automake-1.11/tests/conflnk2.test\n",
            "automake-1.11/tests/backsl3.test\n",
            "automake-1.11/tests/aclocal9.test\n",
            "automake-1.11/tests/subdir6.test\n",
            "automake-1.11/tests/cond8.test\n",
            "automake-1.11/tests/specflg9.test\n",
            "automake-1.11/tests/output12.test\n",
            "automake-1.11/tests/javasubst.test\n",
            "automake-1.11/tests/suffix3.test\n",
            "automake-1.11/tests/acoutpt2.test\n",
            "automake-1.11/tests/pr279.test\n",
            "automake-1.11/tests/distcom6.test\n",
            "automake-1.11/tests/check5.test\n",
            "automake-1.11/tests/nodep2.test\n",
            "automake-1.11/tests/cond31.test\n",
            "automake-1.11/tests/cond15.test\n",
            "automake-1.11/tests/maintclean.test\n",
            "automake-1.11/tests/instmany.test\n",
            "automake-1.11/tests/subobj7.test\n",
            "automake-1.11/tests/subst2.test\n",
            "automake-1.11/tests/python4.test\n",
            "automake-1.11/tests/stamph2.test\n",
            "automake-1.11/tests/Makefile.in\n",
            "automake-1.11/tests/exeext2.test\n",
            "automake-1.11/tests/spelling.test\n",
            "automake-1.11/tests/pluseq5.test\n",
            "automake-1.11/tests/ccnoco.test\n",
            "automake-1.11/tests/defun2.test\n",
            "automake-1.11/tests/cond2.test\n",
            "automake-1.11/tests/vtexi.test\n",
            "automake-1.11/tests/instfail-libtool.test\n",
            "automake-1.11/tests/mdate2.test\n",
            "automake-1.11/tests/libobj7.test\n",
            "automake-1.11/tests/libobj8.test\n",
            "automake-1.11/tests/aclocal.in\n",
            "automake-1.11/tests/lex3.test\n",
            "automake-1.11/tests/cond33.test\n",
            "automake-1.11/tests/colon2.test\n",
            "automake-1.11/tests/version2.test\n",
            "automake-1.11/tests/libobj13.test\n",
            "automake-1.11/tests/reqd.test\n",
            "automake-1.11/tests/noinstdir.test\n",
            "automake-1.11/tests/pluseq2.test\n",
            "automake-1.11/tests/target-cflags.test\n",
            "automake-1.11/tests/conf2.test\n",
            "automake-1.11/tests/libtool8.test\n",
            "automake-1.11/tests/gnits3.test\n",
            "automake-1.11/tests/prefix.test\n",
            "automake-1.11/tests/stdinc.test\n",
            "automake-1.11/tests/libexec.test\n",
            "automake-1.11/tests/link_dist.test\n",
            "automake-1.11/tests/version7.test\n",
            "automake-1.11/tests/subdir4.test\n",
            "automake-1.11/tests/aclocal7.test\n",
            "automake-1.11/tests/checkall.test\n",
            "automake-1.11/tests/dollarvar.test\n",
            "automake-1.11/tests/nodepcomp.test\n",
            "automake-1.11/tests/pluseq7.test\n",
            "automake-1.11/tests/scripts.test\n",
            "automake-1.11/tests/acloca22.test\n",
            "automake-1.11/tests/canon.test\n",
            "automake-1.11/tests/check4.test\n",
            "automake-1.11/tests/ppf77.test\n",
            "automake-1.11/tests/tags.test\n",
            "automake-1.11/tests/libtool4.test\n",
            "automake-1.11/tests/condhook.test\n",
            "automake-1.11/tests/suffix11.test\n",
            "automake-1.11/tests/pr401b.test\n",
            "automake-1.11/tests/cond41.test\n",
            "automake-1.11/tests/suffix8.test\n",
            "automake-1.11/tests/pr9.test\n",
            "automake-1.11/tests/exdir.test\n",
            "automake-1.11/tests/phony.test\n",
            "automake-1.11/tests/subobj5.test\n",
            "automake-1.11/tests/alpha.test\n",
            "automake-1.11/tests/dollar.test\n",
            "automake-1.11/tests/remake2.test\n",
            "automake-1.11/tests/instsh3.test\n",
            "automake-1.11/tests/python8.test\n",
            "automake-1.11/tests/dejagnu4.test\n",
            "automake-1.11/tests/gcj5.test\n",
            "automake-1.11/tests/cond40.test\n",
            "automake-1.11/tests/getopt.test\n",
            "automake-1.11/tests/lisp8.test\n",
            "automake-1.11/tests/ansi10.test\n",
            "automake-1.11/tests/defs.in\n",
            "automake-1.11/tests/alpha2.test\n",
            "automake-1.11/tests/tagsub.test\n",
            "automake-1.11/tests/makej2.test\n",
            "automake-1.11/tests/libobj14.test\n",
            "automake-1.11/tests/subdirbuiltsources.test\n",
            "automake-1.11/tests/maken3-p.test\n",
            "automake-1.11/tests/yacc6.test\n",
            "automake-1.11/tests/cxxlink.test\n",
            "automake-1.11/tests/amsubst.test\n",
            "automake-1.11/tests/cxxnoc.test\n",
            "automake-1.11/tests/pr266.test\n",
            "automake-1.11/tests/suffix7.test\n",
            "automake-1.11/tests/subobj2.test\n",
            "automake-1.11/tests/distcleancheck.test\n",
            "automake-1.11/tests/ext.test\n",
            "automake-1.11/tests/java.test\n",
            "automake-1.11/tests/pr401-p.test\n",
            "automake-1.11/COPYING\n",
            "automake-1.11/doc/\n",
            "automake-1.11/doc/automake.info-2\n",
            "automake-1.11/doc/stamp-vti\n",
            "automake-1.11/doc/amhello-1.0.tar.gz\n",
            "automake-1.11/doc/automake-1.11.1\n",
            "automake-1.11/doc/aclocal.1\n",
            "automake-1.11/doc/automake.texi\n",
            "automake-1.11/doc/Makefile.am\n",
            "automake-1.11/doc/amhello/\n",
            "automake-1.11/doc/amhello/Makefile.am\n",
            "automake-1.11/doc/amhello/README\n",
            "automake-1.11/doc/amhello/configure.ac\n",
            "automake-1.11/doc/amhello/src/\n",
            "automake-1.11/doc/amhello/src/main.c\n",
            "automake-1.11/doc/amhello/src/Makefile.am\n",
            "automake-1.11/doc/version.texi\n",
            "automake-1.11/doc/aclocal-1.11.1\n",
            "automake-1.11/doc/automake.1\n",
            "automake-1.11/doc/Makefile.in\n",
            "automake-1.11/doc/fdl.texi\n",
            "automake-1.11/doc/automake.info\n",
            "automake-1.11/doc/automake.info-1\n",
            "automake-1.11/AUTHORS\n",
            "automake-1.11/ChangeLog.01\n",
            "automake-1.11/NEWS\n",
            "automake-1.11/configure\n",
            "automake-1.11/INSTALL\n",
            "automake-1.11/Makefile.am\n",
            "automake-1.11/aclocal.m4\n",
            "automake-1.11/README\n",
            "automake-1.11/ChangeLog.02\n",
            "automake-1.11/ChangeLog.00\n",
            "automake-1.11/ChangeLog.04\n",
            "automake-1.11/configure.ac\n",
            "automake-1.11/Makefile.in\n",
            "automake-1.11/aclocal.in\n",
            "automake-1.11/lib/\n",
            "automake-1.11/lib/missing\n",
            "automake-1.11/lib/elisp-comp\n",
            "automake-1.11/lib/mdate-sh\n",
            "automake-1.11/lib/py-compile\n",
            "automake-1.11/lib/Automake/\n",
            "automake-1.11/lib/Automake/ChannelDefs.pm\n",
            "automake-1.11/lib/Automake/Channels.pm\n",
            "automake-1.11/lib/Automake/Item.pm\n",
            "automake-1.11/lib/Automake/ItemDef.pm\n",
            "automake-1.11/lib/Automake/Struct.pm\n",
            "automake-1.11/lib/Automake/Wrap.pm\n",
            "automake-1.11/lib/Automake/Options.pm\n",
            "automake-1.11/lib/Automake/XFile.pm\n",
            "automake-1.11/lib/Automake/VarDef.pm\n",
            "automake-1.11/lib/Automake/tests/\n",
            "automake-1.11/lib/Automake/tests/DisjConditions-t.pl\n",
            "automake-1.11/lib/Automake/tests/Wrap.pl\n",
            "automake-1.11/lib/Automake/tests/Condition.pl\n",
            "automake-1.11/lib/Automake/tests/Makefile.am\n",
            "automake-1.11/lib/Automake/tests/Condition-t.pl\n",
            "automake-1.11/lib/Automake/tests/DisjConditions.pl\n",
            "automake-1.11/lib/Automake/tests/Makefile.in\n",
            "automake-1.11/lib/Automake/tests/Version.pl\n",
            "automake-1.11/lib/Automake/Variable.pm\n",
            "automake-1.11/lib/Automake/Config.in\n",
            "automake-1.11/lib/Automake/Version.pm\n",
            "automake-1.11/lib/Automake/General.pm\n",
            "automake-1.11/lib/Automake/Location.pm\n",
            "automake-1.11/lib/Automake/Condition.pm\n",
            "automake-1.11/lib/Automake/Rule.pm\n",
            "automake-1.11/lib/Automake/Makefile.am\n",
            "automake-1.11/lib/Automake/RuleDef.pm\n",
            "automake-1.11/lib/Automake/DisjConditions.pm\n",
            "automake-1.11/lib/Automake/Makefile.in\n",
            "automake-1.11/lib/Automake/Configure_ac.pm\n",
            "automake-1.11/lib/Automake/FileUtils.pm\n",
            "automake-1.11/lib/compile\n",
            "automake-1.11/lib/COPYING\n",
            "automake-1.11/lib/config.sub\n",
            "automake-1.11/lib/mkinstalldirs\n",
            "automake-1.11/lib/install-sh\n",
            "automake-1.11/lib/am/\n",
            "automake-1.11/lib/am/inst-vars.am\n",
            "automake-1.11/lib/am/texinfos.am\n",
            "automake-1.11/lib/am/depend2.am\n",
            "automake-1.11/lib/am/lex.am\n",
            "automake-1.11/lib/am/footer.am\n",
            "automake-1.11/lib/am/clean-hdr.am\n",
            "automake-1.11/lib/am/scripts.am\n",
            "automake-1.11/lib/am/mans-vars.am\n",
            "automake-1.11/lib/am/program.am\n",
            "automake-1.11/lib/am/distdir.am\n",
            "automake-1.11/lib/am/vala.am\n",
            "automake-1.11/lib/am/yacc.am\n",
            "automake-1.11/lib/am/depend.am\n",
            "automake-1.11/lib/am/tags.am\n",
            "automake-1.11/lib/am/check2.am\n",
            "automake-1.11/lib/am/texibuild.am\n",
            "automake-1.11/lib/am/mans.am\n",
            "automake-1.11/lib/am/compile.am\n",
            "automake-1.11/lib/am/library.am\n",
            "automake-1.11/lib/am/ansi2knr.am\n",
            "automake-1.11/lib/am/Makefile.am\n",
            "automake-1.11/lib/am/texi-vers.am\n",
            "automake-1.11/lib/am/header-vars.am\n",
            "automake-1.11/lib/am/data.am\n",
            "automake-1.11/lib/am/progs.am\n",
            "automake-1.11/lib/am/clean.am\n",
            "automake-1.11/lib/am/dejagnu.am\n",
            "automake-1.11/lib/am/install.am\n",
            "automake-1.11/lib/am/ltlibrary.am\n",
            "automake-1.11/lib/am/lang-compile.am\n",
            "automake-1.11/lib/am/check.am\n",
            "automake-1.11/lib/am/Makefile.in\n",
            "automake-1.11/lib/am/libtool.am\n",
            "automake-1.11/lib/am/multilib.am\n",
            "automake-1.11/lib/am/ltlib.am\n",
            "automake-1.11/lib/am/remake-hdr.am\n",
            "automake-1.11/lib/am/header.am\n",
            "automake-1.11/lib/am/libs.am\n",
            "automake-1.11/lib/am/java.am\n",
            "automake-1.11/lib/am/subdirs.am\n",
            "automake-1.11/lib/am/lisp.am\n",
            "automake-1.11/lib/am/configure.am\n",
            "automake-1.11/lib/am/python.am\n",
            "automake-1.11/lib/ansi2knr.c\n",
            "automake-1.11/lib/INSTALL\n",
            "automake-1.11/lib/Makefile.am\n",
            "automake-1.11/lib/symlink-tree\n",
            "automake-1.11/lib/config.guess\n",
            "automake-1.11/lib/depcomp\n",
            "automake-1.11/lib/acinstall\n",
            "automake-1.11/lib/gnupload\n",
            "automake-1.11/lib/texinfo.tex\n",
            "automake-1.11/lib/config-ml.in\n",
            "automake-1.11/lib/ansi2knr.1\n",
            "automake-1.11/lib/Makefile.in\n",
            "automake-1.11/lib/ylwrap\n",
            "automake-1.11/TODO\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for perl... /usr/bin/perl\n",
            "checking whether /usr/bin/perl supports ithreads... yes\n",
            "checking for tex... no\n",
            "checking whether autoconf is installed... no\n",
            "configure: error: Autoconf 2.60 or better is required.\n",
            "    Please make sure it is installed and in your PATH.\n",
            "make: *** No targets specified and no makefile found.  Stop.\n",
            "make: *** No rule to make target 'install'.  Stop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mecab-ko 설치\n",
        "os.chdir('/tmp/')\n",
        "!curl -LO https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.1.tar.gz\n",
        "!tar zxfv mecab-0.996-ko-0.9.1.tar.gz\n",
        "os.chdir('/tmp/mecab-0.996-ko-0.9.1')\n",
        "!./configure\n",
        "!make\n",
        "!make check\n",
        "!make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "597S8Lj0gzNd",
        "outputId": "6e75acd3-5d9f-4d80-bbf4-67800bf181f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1380k  100 1380k    0     0  2048k      0 --:--:-- --:--:-- --:--:-- 2048k\n",
            "mecab-0.996-ko-0.9.1/\n",
            "mecab-0.996-ko-0.9.1/config.h.in\n",
            "mecab-0.996-ko-0.9.1/Makefile.train\n",
            "mecab-0.996-ko-0.9.1/ChangeLog\n",
            "mecab-0.996-ko-0.9.1/configure\n",
            "mecab-0.996-ko-0.9.1/swig/\n",
            "mecab-0.996-ko-0.9.1/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.1/swig/Makefile\n",
            "mecab-0.996-ko-0.9.1/swig/version.h\n",
            "mecab-0.996-ko-0.9.1/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.1/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.1/mecab-config.in\n",
            "mecab-0.996-ko-0.9.1/configure.in\n",
            "mecab-0.996-ko-0.9.1/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.1/aclocal.m4\n",
            "mecab-0.996-ko-0.9.1/mecabrc.in\n",
            "mecab-0.996-ko-0.9.1/INSTALL\n",
            "mecab-0.996-ko-0.9.1/AUTHORS\n",
            "mecab-0.996-ko-0.9.1/example/\n",
            "mecab-0.996-ko-0.9.1/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.1/example/example.cpp\n",
            "mecab-0.996-ko-0.9.1/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.1/example/example.c\n",
            "mecab-0.996-ko-0.9.1/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.1/BSD\n",
            "mecab-0.996-ko-0.9.1/README\n",
            "mecab-0.996-ko-0.9.1/install-sh\n",
            "mecab-0.996-ko-0.9.1/README.md\n",
            "mecab-0.996-ko-0.9.1/CHANGES.md\n",
            "mecab-0.996-ko-0.9.1/missing\n",
            "mecab-0.996-ko-0.9.1/GPL\n",
            "mecab-0.996-ko-0.9.1/man/\n",
            "mecab-0.996-ko-0.9.1/man/mecab.1\n",
            "mecab-0.996-ko-0.9.1/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.1/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.1/config.rpath\n",
            "mecab-0.996-ko-0.9.1/doc/\n",
            "mecab-0.996-ko-0.9.1/doc/feature.html\n",
            "mecab-0.996-ko-0.9.1/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.1/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.1/doc/learn.html\n",
            "mecab-0.996-ko-0.9.1/doc/dic.html\n",
            "mecab-0.996-ko-0.9.1/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.1/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.1/doc/unk.html\n",
            "mecab-0.996-ko-0.9.1/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.1/doc/result.png\n",
            "mecab-0.996-ko-0.9.1/doc/flow.png\n",
            "mecab-0.996-ko-0.9.1/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.1/doc/feature.png\n",
            "mecab-0.996-ko-0.9.1/doc/partial.html\n",
            "mecab-0.996-ko-0.9.1/doc/posid.html\n",
            "mecab-0.996-ko-0.9.1/doc/en/\n",
            "mecab-0.996-ko-0.9.1/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.1/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.1/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.1/doc/index.html\n",
            "mecab-0.996-ko-0.9.1/doc/format.html\n",
            "mecab-0.996-ko-0.9.1/doc/soft.html\n",
            "mecab-0.996-ko-0.9.1/LGPL\n",
            "mecab-0.996-ko-0.9.1/ltmain.sh\n",
            "mecab-0.996-ko-0.9.1/Makefile.in\n",
            "mecab-0.996-ko-0.9.1/COPYING\n",
            "mecab-0.996-ko-0.9.1/Makefile.am\n",
            "mecab-0.996-ko-0.9.1/config.guess\n",
            "mecab-0.996-ko-0.9.1/src/\n",
            "mecab-0.996-ko-0.9.1/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.1/src/param.h\n",
            "mecab-0.996-ko-0.9.1/src/darts.h\n",
            "mecab-0.996-ko-0.9.1/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.1/src/param.cpp\n",
            "mecab-0.996-ko-0.9.1/src/connector.h\n",
            "mecab-0.996-ko-0.9.1/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.1/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.1/src/ucs.h\n",
            "mecab-0.996-ko-0.9.1/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.1/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.1/src/context_id.h\n",
            "mecab-0.996-ko-0.9.1/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.1/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.1/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.1/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.1/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.1/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.1/src/common.h\n",
            "mecab-0.996-ko-0.9.1/src/char_property.h\n",
            "mecab-0.996-ko-0.9.1/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.1/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.1/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.1/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.1/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.1/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.1/src/utils.h\n",
            "mecab-0.996-ko-0.9.1/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.1/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.1/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.1/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.1/src/mecab.h\n",
            "mecab-0.996-ko-0.9.1/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.1/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.1/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.1/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.1/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.1/src/mmap.h\n",
            "mecab-0.996-ko-0.9.1/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.1/src/make.bat\n",
            "mecab-0.996-ko-0.9.1/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.1/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.1/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.1/src/freelist.h\n",
            "mecab-0.996-ko-0.9.1/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.1/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.1/src/thread.h\n",
            "mecab-0.996-ko-0.9.1/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.1/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.1/src/writer.h\n",
            "mecab-0.996-ko-0.9.1/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.1/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.1/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.1/src/winmain.h\n",
            "mecab-0.996-ko-0.9.1/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.1/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.1/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.1/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.1/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.1/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.1/config.sub\n",
            "mecab-0.996-ko-0.9.1/tests/\n",
            "mecab-0.996-ko-0.9.1/tests/t9/\n",
            "mecab-0.996-ko-0.9.1/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/t9/test\n",
            "mecab-0.996-ko-0.9.1/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.1/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.1/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.1/tests/eval/\n",
            "mecab-0.996-ko-0.9.1/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.1/tests/eval/system\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.1/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.1/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.1/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.1/tests/latin/\n",
            "mecab-0.996-ko-0.9.1/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/latin/test\n",
            "mecab-0.996-ko-0.9.1/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.1/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.1/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.1/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.1/NEWS\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: config.h is unchanged\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.1'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mecab-ko-dic 설치\n",
        "os.chdir('/tmp')\n",
        "!curl -LO https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.0.1-20150920.tar.gz\n",
        "!tar -zxvf mecab-ko-dic-2.0.1-20150920.tar.gz\n",
        "os.chdir('/tmp/mecab-ko-dic-2.0.1-20150920')\n",
        "!./autogen.sh\n",
        "!./configure\n",
        "!make\n",
        "# !sh -c 'echo \"dicdir=/usr/local/lib/mecab/dic/mecab-ko-dic\" > /usr/local/etc/mecabrc'\n",
        "!make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMY0XNFYg05V",
        "outputId": "061bd608-08a9-4430-9b5d-ffdd8defda66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 46.3M  100 46.3M    0     0  38.6M      0  0:00:01  0:00:01 --:--:-- 99.6M\n",
            "mecab-ko-dic-2.0.1-20150920/\n",
            "mecab-ko-dic-2.0.1-20150920/configure.ac\n",
            "mecab-ko-dic-2.0.1-20150920/Person-actor.csv\n",
            "mecab-ko-dic-2.0.1-20150920/IC.csv\n",
            "mecab-ko-dic-2.0.1-20150920/model.def\n",
            "mecab-ko-dic-2.0.1-20150920/user-dic/\n",
            "mecab-ko-dic-2.0.1-20150920/user-dic/place.csv\n",
            "mecab-ko-dic-2.0.1-20150920/user-dic/README.md\n",
            "mecab-ko-dic-2.0.1-20150920/user-dic/person.csv\n",
            "mecab-ko-dic-2.0.1-20150920/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Place.csv\n",
            "mecab-ko-dic-2.0.1-20150920/rewrite.def\n",
            "mecab-ko-dic-2.0.1-20150920/tools/\n",
            "mecab-ko-dic-2.0.1-20150920/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.0.1-20150920/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.0.1-20150920/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.0.1-20150920/right-id.def\n",
            "mecab-ko-dic-2.0.1-20150920/VX.csv\n",
            "mecab-ko-dic-2.0.1-20150920/XR.csv\n",
            "mecab-ko-dic-2.0.1-20150920/NP.csv\n",
            "mecab-ko-dic-2.0.1-20150920/XSN.csv\n",
            "mecab-ko-dic-2.0.1-20150920/feature.def\n",
            "mecab-ko-dic-2.0.1-20150920/README\n",
            "mecab-ko-dic-2.0.1-20150920/pos-id.def\n",
            "mecab-ko-dic-2.0.1-20150920/COPYING\n",
            "mecab-ko-dic-2.0.1-20150920/ETM.csv\n",
            "mecab-ko-dic-2.0.1-20150920/CoinedWord.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Symbol.csv\n",
            "mecab-ko-dic-2.0.1-20150920/EC.csv\n",
            "mecab-ko-dic-2.0.1-20150920/INSTALL\n",
            "mecab-ko-dic-2.0.1-20150920/EF.csv\n",
            "mecab-ko-dic-2.0.1-20150920/unk.def\n",
            "mecab-ko-dic-2.0.1-20150920/J.csv\n",
            "mecab-ko-dic-2.0.1-20150920/ETN.csv\n",
            "mecab-ko-dic-2.0.1-20150920/NNBC.csv\n",
            "mecab-ko-dic-2.0.1-20150920/XSV.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Group.csv\n",
            "mecab-ko-dic-2.0.1-20150920/dicrc\n",
            "mecab-ko-dic-2.0.1-20150920/VCP.csv\n",
            "mecab-ko-dic-2.0.1-20150920/EP.csv\n",
            "mecab-ko-dic-2.0.1-20150920/VV.csv\n",
            "mecab-ko-dic-2.0.1-20150920/NNP.csv\n",
            "mecab-ko-dic-2.0.1-20150920/NR.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Preanalysis.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Person.csv\n",
            "mecab-ko-dic-2.0.1-20150920/left-id.def\n",
            "mecab-ko-dic-2.0.1-20150920/Makefile.am\n",
            "mecab-ko-dic-2.0.1-20150920/NorthKorea.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Inflect.csv\n",
            "mecab-ko-dic-2.0.1-20150920/configure\n",
            "mecab-ko-dic-2.0.1-20150920/VCN.csv\n",
            "mecab-ko-dic-2.0.1-20150920/MAJ.csv\n",
            "mecab-ko-dic-2.0.1-20150920/XSA.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Foreign.csv\n",
            "mecab-ko-dic-2.0.1-20150920/NNB.csv\n",
            "mecab-ko-dic-2.0.1-20150920/VA.csv\n",
            "mecab-ko-dic-2.0.1-20150920/XPN.csv\n",
            "mecab-ko-dic-2.0.1-20150920/clean\n",
            "mecab-ko-dic-2.0.1-20150920/ChangeLog\n",
            "mecab-ko-dic-2.0.1-20150920/install-sh\n",
            "mecab-ko-dic-2.0.1-20150920/Wikipedia.csv\n",
            "mecab-ko-dic-2.0.1-20150920/autogen.sh\n",
            "mecab-ko-dic-2.0.1-20150920/Place-station.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Place-address.csv\n",
            "mecab-ko-dic-2.0.1-20150920/AUTHORS\n",
            "mecab-ko-dic-2.0.1-20150920/Hanja.csv\n",
            "mecab-ko-dic-2.0.1-20150920/MM.csv\n",
            "mecab-ko-dic-2.0.1-20150920/missing\n",
            "mecab-ko-dic-2.0.1-20150920/.keep\n",
            "mecab-ko-dic-2.0.1-20150920/char.def\n",
            "mecab-ko-dic-2.0.1-20150920/matrix.def\n",
            "mecab-ko-dic-2.0.1-20150920/NEWS\n",
            "mecab-ko-dic-2.0.1-20150920/MAG.csv\n",
            "mecab-ko-dic-2.0.1-20150920/NNG.csv\n",
            "mecab-ko-dic-2.0.1-20150920/Makefile.in\n",
            "Looking in current directory for macros.\n",
            "./autogen.sh: 11: ./autogen.sh: aclocal: not found\n",
            "./autogen.sh: 14: ./autogen.sh: autoconf: not found\n",
            "./autogen.sh: 15: ./autogen.sh: automake: not found\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            " cd . && /bin/bash /tmp/mecab-ko-dic-2.0.1-20150920/missing --run automake-1.11 --gnu\n",
            "/tmp/mecab-ko-dic-2.0.1-20150920/missing: line 52: automake-1.11: command not found\n",
            "WARNING: `automake-1.11' is missing on your system.  You should only need it if\n",
            "         you modified `Makefile.am', `acinclude.m4' or `configure.ac'.\n",
            "         You might want to install the `Automake' and `Perl' packages.\n",
            "         Grab them from any GNU archive site.\n",
            "CDPATH=\"${ZSH_VERSION+.}:\" && cd . && /bin/bash /tmp/mecab-ko-dic-2.0.1-20150920/missing --run autoconf\n",
            "/tmp/mecab-ko-dic-2.0.1-20150920/missing: line 52: autoconf: command not found\n",
            "WARNING: `autoconf' is missing on your system.  You should only need it if\n",
            "         you modified `configure.ac'.  You might want to install the\n",
            "         `Autoconf' and `GNU m4' packages.  Grab them from any GNU\n",
            "         archive site.\n",
            "/bin/bash ./config.status --recheck\n",
            "running CONFIG_SHELL=/bin/bash /bin/bash ./configure --no-create --no-recursion\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "configure: creating ./config.status\n",
            " /bin/bash ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "/usr/local/libexec/mecab/mecab-dict-index: error while loading shared libraries: libmecab.so.2: cannot open shared object file: No such file or directory\n",
            "Makefile:555: recipe for target 'model.bin' failed\n",
            "make: *** [model.bin] Error 127\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "/usr/local/libexec/mecab/mecab-dict-index: error while loading shared libraries: libmecab.so.2: cannot open shared object file: No such file or directory\n",
            "Makefile:555: recipe for target 'model.bin' failed\n",
            "make: *** [model.bin] Error 127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mecab-python 설치: python3 기준\n",
        "os.chdir('/content')\n",
        "!git clone https://bitbucket.org/eunjeon/mecab-python-0.996.git\n",
        "os.chdir('/content/mecab-python-0.996')\n",
        "!python3 setup.py build\n",
        "!python3 setup.py install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClKLf0PKg31c",
        "outputId": "e59380a9-7d67-497c-fa9e-f4ed47053599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mecab-python-0.996' already exists and is not an empty directory.\n",
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "running build_ext\n",
            "running install_lib\n",
            "running install_egg_info\n",
            "Removing /usr/local/lib/python3.7/dist-packages/mecab_python-0.996_ko_0.9.0.egg-info\n",
            "Writing /usr/local/lib/python3.7/dist-packages/mecab_python-0.996_ko_0.9.0.egg-info\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/usr/local/lib/python3.7/dist-packages/konlpy/java')\n",
        "os.getcwd() \n",
        "os.makedirs('./new_dic')"
      ],
      "metadata": {
        "id": "NiiZpJftg5qS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "cd11d121-8fef-4856-941b-44de5b5b97f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-47db084fdaf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr/local/lib/python3.7/dist-packages/konlpy/java'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./new_dic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Cannot rely on checking for EEXIST, since the operating system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './new_dic'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#현재 경로 확인\n",
        "os.getcwd()\n",
        "os.chdir('/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic')"
      ],
      "metadata": {
        "id": "OcfsLbskg7aG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_dic 폴더에 okt 사전 압축 파일 풀기\n",
        "!jar xvf ../open-korean-text-2.1.0.jar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQWJEd8Xg9b-",
        "outputId": "713b039f-4ba6-4a73-d40e-7b0cd2c0b590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  created: META-INF/\n",
            " inflated: META-INF/MANIFEST.MF\n",
            "  created: org/\n",
            "  created: org/openkoreantext/\n",
            "  created: org/openkoreantext/processor/\n",
            "  created: org/openkoreantext/processor/normalizer/\n",
            "  created: org/openkoreantext/processor/phrase_extractor/\n",
            "  created: org/openkoreantext/processor/qa/\n",
            "  created: org/openkoreantext/processor/stemmer/\n",
            "  created: org/openkoreantext/processor/tokenizer/\n",
            "  created: org/openkoreantext/processor/tools/\n",
            "  created: org/openkoreantext/processor/util/\n",
            "  created: org/openkoreantext/processor/util/adjective/\n",
            "  created: org/openkoreantext/processor/util/adverb/\n",
            "  created: org/openkoreantext/processor/util/auxiliary/\n",
            "  created: org/openkoreantext/processor/util/freq/\n",
            "  created: org/openkoreantext/processor/util/josa/\n",
            "  created: org/openkoreantext/processor/util/noun/\n",
            "  created: org/openkoreantext/processor/util/substantives/\n",
            "  created: org/openkoreantext/processor/util/typos/\n",
            "  created: org/openkoreantext/processor/util/verb/\n",
            " inflated: org/openkoreantext/processor/KoreanPosJava.class\n",
            " inflated: org/openkoreantext/processor/KoreanTokenJava.class\n",
            " inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer$.class\n",
            " inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment$.class\n",
            " inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment.class\n",
            " inflated: org/openkoreantext/processor/normalizer/KoreanNormalizer.class\n",
            " inflated: org/openkoreantext/processor/OpenKoreanTextProcessor$.class\n",
            " inflated: org/openkoreantext/processor/OpenKoreanTextProcessor.class\n",
            " inflated: org/openkoreantext/processor/OpenKoreanTextProcessorJava.class\n",
            " inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$.class\n",
            " inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase$.class\n",
            " inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase.class\n",
            " inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer$.class\n",
            " inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer.class\n",
            " inflated: org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns$.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet$.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchGetUnknownNouns.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets$.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime$.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime.class\n",
            " inflated: org/openkoreantext/processor/qa/BatchTokenizeTweets.class\n",
            " inflated: org/openkoreantext/processor/qa/KoreanProcessorSandbox$.class\n",
            " inflated: org/openkoreantext/processor/qa/KoreanProcessorSandbox.class\n",
            " inflated: org/openkoreantext/processor/stemmer/KoreanStemmer$.class\n",
            " inflated: org/openkoreantext/processor/stemmer/KoreanStemmer.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanChunk$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanChunk.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanChunker$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanChunker.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanDetokenizer$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanDetokenizer.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/KoreanTokenizer.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/ParsedChunk$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/ParsedChunk.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/Sentence$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/Sentence.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/TokenizerProfile$.class\n",
            " inflated: org/openkoreantext/processor/tokenizer/TokenizerProfile.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateChunkParsingCandidates$.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateChunkParsingCandidates.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateConjugationExamples$.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample$.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateConjugationExamples.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateParsingExamples$.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample$.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample.class\n",
            " inflated: org/openkoreantext/processor/tools/CreateParsingExamples.class\n",
            " inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$.class\n",
            " inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample$.class\n",
            " inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample.class\n",
            " inflated: org/openkoreantext/processor/tools/CreatePhraseExtractionExamples.class\n",
            " inflated: org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries$.class\n",
            " inflated: org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries.class\n",
            " inflated: org/openkoreantext/processor/tools/Runnable.class\n",
            " inflated: org/openkoreantext/processor/tools/UpdateAllTheExamples$.class\n",
            " inflated: org/openkoreantext/processor/tools/UpdateAllTheExamples.class\n",
            " inflated: org/openkoreantext/processor/util/adjective/adjective.txt\n",
            " inflated: org/openkoreantext/processor/util/adverb/adverb.txt\n",
            " inflated: org/openkoreantext/processor/util/auxiliary/conjunctions.txt\n",
            " inflated: org/openkoreantext/processor/util/auxiliary/determiner.txt\n",
            " inflated: org/openkoreantext/processor/util/auxiliary/exclamation.txt\n",
            " inflated: org/openkoreantext/processor/util/CharacterUtils$CharacterBuffer.class\n",
            " inflated: org/openkoreantext/processor/util/CharacterUtils$Java4CharacterUtils.class\n",
            " inflated: org/openkoreantext/processor/util/CharacterUtils$Java5CharacterUtils.class\n",
            " inflated: org/openkoreantext/processor/util/CharacterUtils.class\n",
            " inflated: org/openkoreantext/processor/util/CharArrayMap$1.class\n",
            " inflated: org/openkoreantext/processor/util/CharArrayMap$EmptyCharArrayMap.class\n",
            " inflated: org/openkoreantext/processor/util/CharArrayMap$EntryIterator.class\n",
            " inflated: org/openkoreantext/processor/util/CharArrayMap$EntrySet.class\n",
            " inflated: org/openkoreantext/processor/util/CharArrayMap$MapEntry.class\n",
            " inflated: org/openkoreantext/processor/util/CharArrayMap$UnmodifiableCharArrayMap.class\n",
            " inflated: org/openkoreantext/processor/util/CharArrayMap.class\n",
            " inflated: org/openkoreantext/processor/util/CharArraySet.class\n",
            " inflated: org/openkoreantext/processor/util/example_chunks.txt\n",
            " inflated: org/openkoreantext/processor/util/example_tweets.txt\n",
            " inflated: org/openkoreantext/processor/util/freq/entity-freq.txt.gz\n",
            " inflated: org/openkoreantext/processor/util/Hangul$.class\n",
            " inflated: org/openkoreantext/processor/util/Hangul$DoubleCoda$.class\n",
            " inflated: org/openkoreantext/processor/util/Hangul$DoubleCoda.class\n",
            " inflated: org/openkoreantext/processor/util/Hangul$HangulChar$.class\n",
            " inflated: org/openkoreantext/processor/util/Hangul$HangulChar.class\n",
            " inflated: org/openkoreantext/processor/util/Hangul.class\n",
            " inflated: org/openkoreantext/processor/util/josa/josa.txt\n",
            " inflated: org/openkoreantext/processor/util/KoreanConjugation$.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanConjugation.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanDictionaryProvider$.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanDictionaryProvider.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanPos$.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie$.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanPos.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanSubstantive$.class\n",
            " inflated: org/openkoreantext/processor/util/KoreanSubstantive.class\n",
            " inflated: org/openkoreantext/processor/util/noun/bible.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/company_names.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/congress.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/entities.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/foreign.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/geolocations.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/kpop.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/lol.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/names.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/nouns.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/pokemon.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/profane.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/slangs.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/spam.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/twitter.txt\n",
            " inflated: org/openkoreantext/processor/util/noun/wikipedia_title_nouns.txt\n",
            " inflated: org/openkoreantext/processor/util/substantives/family_names.txt\n",
            " inflated: org/openkoreantext/processor/util/substantives/given_names.txt\n",
            " inflated: org/openkoreantext/processor/util/substantives/modifier.txt\n",
            " inflated: org/openkoreantext/processor/util/substantives/suffix.txt\n",
            " inflated: org/openkoreantext/processor/util/typos/typos.txt\n",
            " inflated: org/openkoreantext/processor/util/verb/eomi.txt\n",
            " inflated: org/openkoreantext/processor/util/verb/pre_eomi.txt\n",
            " inflated: org/openkoreantext/processor/util/verb/verb.txt\n",
            " inflated: org/openkoreantext/processor/util/verb/verb_prefix.txt\n",
            "  created: META-INF/maven/\n",
            "  created: META-INF/maven/org.openkoreantext/\n",
            "  created: META-INF/maven/org.openkoreantext/open-korean-text/\n",
            " inflated: META-INF/maven/org.openkoreantext/open-korean-text/pom.xml\n",
            " inflated: META-INF/maven/org.openkoreantext/open-korean-text/pom.properties\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 원하는 품사의 파일을 열어 사용자 사전에 추가\n",
        "with open(f\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/noun/company_names.txt\") as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "YJ_P7QyPg-oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 단어 추가\n",
        "data += '샤오미\\n화웨이\\n애플\\n소니\\n레노버\\n한성'\n",
        "\n",
        "# 파일 새롭게 저장\n",
        "with open(\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/noun/company_names.txt\", 'w') as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "ksxJAP7Ig__F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원하는 품사의 파일을 열어 사용자 사전에 추가\n",
        "with open(f\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/noun/nouns.txt\") as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "ZuFUzH_ChBLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 단어 추가\n",
        "data += '아이폰\\n아이패드\\n홍미노트\\n갤럭시\\n갤럭시울트라\\n갤럭시핏\\n노치\\n가성비\\n갓성비\\n노캔\\n노이즈캔슬링\\n에어팟\\n에어팟프로\\n버즈프로\\n갤탭\\n갤럭시\\n플립\\n폴더블\\n힌지\\n프로맥스\\n패키징\\n태블릿\\n패드\\n맥북\\n미밴드\\n이어팁\\n와파\\n와이파이\\n셔터\\n스펙\\n펀치홀\\n프맥\\n울트라\\n커널\\n이어폰\\n엣지\\n망작\\n카툭튀\\n베젤\\n정발\\n포코\\n삼성페이\\n삼페\\n애플페이\\n라이트닝\\n페이스아이디\\n터치아이디\\n다크모드\\n역체감\\n보케\\n시네마틱\\n비스포크\\n글라스틱\\n번인\\n스냅드래곤\\n인덕션\\n환공포증\\n팀쿡'\n",
        "\n",
        "# 파일 새롭게 저장\n",
        "with open(\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/noun/nouns.txt\", 'w') as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "AGJyhGgBhDVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원하는 품사의 파일을 열어 사용자 사전에 추가\n",
        "with open(f\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/noun/slangs.txt\") as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "lvyHOOF8hEkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 단어 추가\n",
        "data += '킹받네\\n존버\\n갬성\\n갬승\\n창렬\\n혜자\\n존나\\n졸라\\n뇌절\\n뇌이징\\n앱등이\\n삼엽충\\n애플빠\\n뽐뿌\\n광탈\\n케바케\\n개추\\n노답\\n떡상\\n떡락\\n띵작\\n넘사\\n믿거\\n할말하않\\n강추\\n비추\\n정뚝떨\\n호갱\\n망성비\\n손절\\n에바\\n개에바\\n원픽\\호불호'\n",
        "\n",
        "# 파일 새롭게 저장\n",
        "with open(\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/noun/slangs.txt\", 'w') as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "hers7rtLhF1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원하는 품사의 파일을 열어 사용자 사전에 추가\n",
        "with open(f\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/josa/josa.txt\") as f:\n",
        "  data = f.read()"
      ],
      "metadata": {
        "id": "gsExeeIGhHC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 단어 추가\n",
        "data += '는데\\n은데\\n한데\\n긴한데\\n음\\n슴\\n셈\\n때메\\n땜에\\n니까\\n'\n",
        "\n",
        "# 파일 새롭게 저장\n",
        "with open(\"/usr/local/lib/python3.7/dist-packages/konlpy/java/new_dic/org/openkoreantext/processor/util/josa/josa.txt\", 'w') as f:\n",
        "    f.write(data)"
      ],
      "metadata": {
        "id": "DQnBdJ9mhH72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#재압축해주기\n",
        "os.chdir('/usr/local/lib/python3.7/dist-packages/konlpy/java')\n",
        "!jar cvf ../open-korean-text-2.1.0.jar *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeTGJMyUhJJp",
        "outputId": "51d727fa-7506-458e-d110-1010465b5f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added manifest\n",
            "adding: aho-corasick.jar(in = 79138) (out= 76068)(deflated 3%)\n",
            "adding: bin/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/kkma/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/kkma/KkmaInterface$4.class(in = 471) (out= 305)(deflated 35%)\n",
            "adding: bin/kr/lucypark/kkma/KkmaInterface$3.class(in = 469) (out= 312)(deflated 33%)\n",
            "adding: bin/kr/lucypark/kkma/KkmaInterface.class(in = 2762) (out= 1476)(deflated 46%)\n",
            "adding: bin/kr/lucypark/kkma/KkmaInterface$2.class(in = 455) (out= 291)(deflated 36%)\n",
            "adding: bin/kr/lucypark/kkma/KkmaInterface$1.class(in = 453) (out= 297)(deflated 34%)\n",
            "adding: bin/kr/lucypark/okt/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/okt/OktInterface.class(in = 3075) (out= 1460)(deflated 52%)\n",
            "adding: bin/kr/lucypark/jhannanum/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/jhannanum/hannanum/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/jhannanum/hannanum/WorkflowFactory.class(in = 2931) (out= 1095)(deflated 62%)\n",
            "adding: bin/kr/lucypark/jhannanum/comm/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/jhannanum/comm/HannanumInterface.class(in = 3352) (out= 1633)(deflated 51%)\n",
            "adding: bin/kr/lucypark/komoran/(in = 0) (out= 0)(stored 0%)\n",
            "adding: bin/kr/lucypark/komoran/KomoranInterface.class(in = 2460) (out= 1213)(deflated 50%)\n",
            "adding: conf/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/MajorPlugin/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/MajorPlugin/PosTagger/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/MajorPlugin/PosTagger/HmmPosTagger.json(in = 1216) (out= 640)(deflated 47%)\n",
            "adding: conf/plugin/MajorPlugin/MorphAnalyzer/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/MajorPlugin/MorphAnalyzer/ChartMorphAnalyzer.json(in = 2203) (out= 1085)(deflated 50%)\n",
            "adding: conf/plugin/SupplementPlugin/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/SupplementPlugin/MorphemeProcessor/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/SupplementPlugin/MorphemeProcessor/UnknownMorphProcessor.json(in = 457) (out= 332)(deflated 27%)\n",
            "adding: conf/plugin/SupplementPlugin/MorphemeProcessor/SimpleMAResult09.json(in = 677) (out= 468)(deflated 30%)\n",
            "adding: conf/plugin/SupplementPlugin/MorphemeProcessor/SimpleMAResult22.json(in = 943) (out= 594)(deflated 37%)\n",
            "adding: conf/plugin/SupplementPlugin/PosProcessor/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/SupplementPlugin/PosProcessor/NounExtractor.json(in = 319) (out= 244)(deflated 23%)\n",
            "adding: conf/plugin/SupplementPlugin/PosProcessor/SimplePOSResult09.json(in = 592) (out= 420)(deflated 29%)\n",
            "adding: conf/plugin/SupplementPlugin/PosProcessor/SimplePOSResult22.json(in = 858) (out= 541)(deflated 36%)\n",
            "adding: conf/plugin/SupplementPlugin/PlainTextProcessor/(in = 0) (out= 0)(stored 0%)\n",
            "adding: conf/plugin/SupplementPlugin/PlainTextProcessor/InformalSentenceFilter.json(in = 950) (out= 568)(deflated 40%)\n",
            "adding: conf/plugin/SupplementPlugin/PlainTextProcessor/SentenceSegmentor.json(in = 886) (out= 515)(deflated 41%)\n",
            "adding: data/(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/kE/(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/kE/__init__.py(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/kE/dic_analyzed.txt(in = 13231) (out= 3664)(deflated 72%)\n",
            "adding: data/kE/connections.txt(in = 1923) (out= 620)(deflated 67%)\n",
            "adding: data/kE/connections_not.txt(in = 211) (out= 167)(deflated 20%)\n",
            "adding: data/kE/__pycache__/(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/kE/__pycache__/__init__.cpython-37.pyc(in = 157) (out= 128)(deflated 18%)\n",
            "adding: data/kE/dic_user.txt(in = 167) (out= 135)(deflated 19%)\n",
            "adding: data/kE/dic_system.txt(in = 4602635) (out= 1153147)(deflated 74%)\n",
            "adding: data/kE/tag_set.txt(in = 4035) (out= 1436)(deflated 64%)\n",
            "adding: data/stat/(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/stat/__init__.py(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/stat/__pycache__/(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/stat/__pycache__/__init__.cpython-37.pyc(in = 159) (out= 130)(deflated 18%)\n",
            "adding: data/stat/PTT.pos(in = 12165) (out= 5153)(deflated 57%)\n",
            "adding: data/stat/PTT.wp(in = 24368) (out= 10707)(deflated 56%)\n",
            "adding: data/stat/PWT.pos(in = 190722) (out= 45476)(deflated 76%)\n",
            "adding: data/models/(in = 0) (out= 0)(stored 0%)\n",
            "adding: data/models/observation.model(in = 2933941) (out= 2933253)(deflated 0%)\n",
            "adding: data/models/irregular.model(in = 191851) (out= 191911)(deflated 0%)\n",
            "adding: data/models/transition.model(in = 6703) (out= 6708)(deflated 0%)\n",
            "adding: data/models/pos.table(in = 295) (out= 205)(deflated 30%)\n",
            "adding: jhannanum-0.8.4.jar(in = 164665) (out= 151367)(deflated 8%)\n",
            "adding: kkma-2.0.jar(in = 7722928) (out= 7707040)(deflated 0%)\n",
            "adding: komoran-3.0.jar(in = 133514) (out= 119633)(deflated 10%)\n",
            "adding: new_dic/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/stemmer/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/stemmer/KoreanStemmer$.class(in = 7044) (out= 2892)(deflated 58%)\n",
            "adding: new_dic/org/openkoreantext/processor/stemmer/KoreanStemmer.class(in = 1439) (out= 972)(deflated 32%)\n",
            "adding: new_dic/org/openkoreantext/processor/normalizer/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/normalizer/KoreanNormalizer.class(in = 2980) (out= 2181)(deflated 26%)\n",
            "adding: new_dic/org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment.class(in = 3470) (out= 1422)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/normalizer/KoreanNormalizer$Segment$.class(in = 2577) (out= 989)(deflated 61%)\n",
            "adding: new_dic/org/openkoreantext/processor/normalizer/KoreanNormalizer$.class(in = 11553) (out= 5102)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/KoreanPosJava.class(in = 2457) (out= 1241)(deflated 49%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie$.class(in = 2862) (out= 1067)(deflated 62%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanDetokenizer$.class(in = 9889) (out= 4174)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/ParsedChunk$.class(in = 3973) (out= 1500)(deflated 62%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch$.class(in = 2893) (out= 1136)(deflated 60%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer.class(in = 6968) (out= 4384)(deflated 37%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken.class(in = 6336) (out= 2633)(deflated 58%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanChunker$.class(in = 17975) (out= 6790)(deflated 62%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanChunk$.class(in = 2361) (out= 1010)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanChunk.class(in = 5611) (out= 2907)(deflated 48%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/Sentence.class(in = 5985) (out= 3125)(deflated 47%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse.class(in = 4616) (out= 1645)(deflated 64%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer$PossibleTrie.class(in = 3399) (out= 1429)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/TokenizerProfile.class(in = 16403) (out= 6666)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanChunker.class(in = 4232) (out= 2887)(deflated 31%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter.class(in = 1092) (out= 712)(deflated 34%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer$KoreanToken$.class(in = 3976) (out= 1402)(deflated 64%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer$CandidateParse$.class(in = 3459) (out= 1111)(deflated 67%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanDetokenizer.class(in = 1660) (out= 1133)(deflated 31%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanChunker$ChunkMatch.class(in = 4043) (out= 1704)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanSentenceSplitter$.class(in = 3359) (out= 1497)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/KoreanTokenizer$.class(in = 25564) (out= 8451)(deflated 66%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/TokenizerProfile$.class(in = 8169) (out= 2408)(deflated 70%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/Sentence$.class(in = 2339) (out= 1012)(deflated 56%)\n",
            "adding: new_dic/org/openkoreantext/processor/tokenizer/ParsedChunk.class(in = 20517) (out= 8914)(deflated 56%)\n",
            "adding: new_dic/org/openkoreantext/processor/OpenKoreanTextProcessorJava.class(in = 5901) (out= 1995)(deflated 66%)\n",
            "adding: new_dic/org/openkoreantext/processor/OpenKoreanTextProcessor.class(in = 4428) (out= 1997)(deflated 54%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries.class(in = 1117) (out= 823)(deflated 26%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateChunkParsingCandidates$.class(in = 5487) (out= 2305)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateConjugationExamples$.class(in = 5881) (out= 2385)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/UpdateAllTheExamples.class(in = 1089) (out= 756)(deflated 30%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/UpdateAllTheExamples$.class(in = 4383) (out= 1794)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateParsingExamples.class(in = 2427) (out= 1732)(deflated 28%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample.class(in = 3569) (out= 1415)(deflated 60%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateConjugationExamples$ConjugationExample$.class(in = 2787) (out= 997)(deflated 64%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/DeduplicateAndSortDictionaries$.class(in = 7154) (out= 3133)(deflated 56%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/Runnable.class(in = 964) (out= 694)(deflated 28%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateChunkParsingCandidates.class(in = 833) (out= 566)(deflated 32%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample$.class(in = 2974) (out= 1020)(deflated 65%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample$.class(in = 2842) (out= 1010)(deflated 64%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateParsingExamples$ParsingExample.class(in = 3718) (out= 1429)(deflated 61%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateParsingExamples$.class(in = 5517) (out= 2327)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$PhraseExample.class(in = 3825) (out= 1443)(deflated 62%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreatePhraseExtractionExamples$.class(in = 5989) (out= 2472)(deflated 58%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreatePhraseExtractionExamples.class(in = 2516) (out= 1784)(deflated 29%)\n",
            "adding: new_dic/org/openkoreantext/processor/tools/CreateConjugationExamples.class(in = 2367) (out= 1659)(deflated 29%)\n",
            "adding: new_dic/org/openkoreantext/processor/OpenKoreanTextProcessor$.class(in = 7716) (out= 2400)(deflated 68%)\n",
            "adding: new_dic/org/openkoreantext/processor/phrase_extractor/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase$.class(in = 3358) (out= 1148)(deflated 65%)\n",
            "adding: new_dic/org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$KoreanPhrase.class(in = 6942) (out= 2591)(deflated 62%)\n",
            "adding: new_dic/org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer.class(in = 4857) (out= 1609)(deflated 66%)\n",
            "adding: new_dic/org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor.class(in = 6005) (out= 3967)(deflated 33%)\n",
            "adding: new_dic/org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$.class(in = 37855) (out= 12404)(deflated 67%)\n",
            "adding: new_dic/org/openkoreantext/processor/phrase_extractor/KoreanPhraseExtractor$PhraseBuffer$.class(in = 3564) (out= 1087)(deflated 69%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/josa/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/josa/josa.txt(in = 5283) (out= 1510)(deflated 71%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/nouns.txt(in = 219922) (out= 84447)(deflated 61%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/foreign.txt(in = 10485) (out= 4686)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/entities.txt(in = 108142) (out= 44095)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/profane.txt(in = 569) (out= 337)(deflated 40%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/wikipedia_title_nouns.txt(in = 1971964) (out= 686708)(deflated 65%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/twitter.txt(in = 254) (out= 162)(deflated 36%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/names.txt(in = 903) (out= 549)(deflated 39%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/geolocations.txt(in = 5423) (out= 2267)(deflated 58%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/congress.txt(in = 26494) (out= 9351)(deflated 64%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/bible.txt(in = 2032) (out= 1005)(deflated 50%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/lol.txt(in = 1337) (out= 744)(deflated 44%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/pokemon.txt(in = 1781) (out= 965)(deflated 45%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/kpop.txt(in = 5371) (out= 2495)(deflated 53%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/slangs.txt(in = 1838) (out= 1079)(deflated 41%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/spam.txt(in = 202) (out= 157)(deflated 22%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/noun/company_names.txt(in = 1681) (out= 933)(deflated 44%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/Hangul$HangulChar$.class(in = 2389) (out= 1022)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanSubstantive.class(in = 1336) (out= 1087)(deflated 18%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/verb/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/verb/eomi.txt(in = 12618) (out= 3556)(deflated 71%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/verb/pre_eomi.txt(in = 285) (out= 185)(deflated 35%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/verb/verb_prefix.txt(in = 47) (out= 52)(deflated -10%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/verb/verb.txt(in = 32758) (out= 10723)(deflated 67%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/example_chunks.txt(in = 522978) (out= 163253)(deflated 68%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArrayMap.class(in = 11923) (out= 4878)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArraySet.class(in = 4886) (out= 1944)(deflated 60%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/Hangul$DoubleCoda.class(in = 2930) (out= 1348)(deflated 53%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharacterUtils$CharacterBuffer.class(in = 1634) (out= 659)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanConjugation.class(in = 1550) (out= 1237)(deflated 20%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/example_tweets.txt(in = 86271) (out= 38336)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/adjective/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/adjective/adjective.txt(in = 27250) (out= 9357)(deflated 65%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanPos$.class(in = 12173) (out= 4669)(deflated 61%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArrayMap$EntrySet.class(in = 2788) (out= 1181)(deflated 57%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/Hangul$.class(in = 7625) (out= 3114)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArrayMap$EntryIterator.class(in = 3118) (out= 1270)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/Hangul$HangulChar.class(in = 3185) (out= 1421)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArrayMap$1.class(in = 1531) (out= 571)(deflated 62%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArrayMap$UnmodifiableCharArrayMap.class(in = 3062) (out= 859)(deflated 71%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanPos.class(in = 6890) (out= 3877)(deflated 43%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharacterUtils$Java5CharacterUtils.class(in = 2824) (out= 1393)(deflated 50%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/freq/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/freq/entity-freq.txt.gz(in = 385753) (out= 385873)(deflated 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArrayMap$EmptyCharArrayMap.class(in = 2053) (out= 725)(deflated 64%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/Hangul.class(in = 3981) (out= 2731)(deflated 31%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanSubstantive$.class(in = 14990) (out= 6195)(deflated 58%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharArrayMap$MapEntry.class(in = 2433) (out= 1078)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharacterUtils$Java4CharacterUtils.class(in = 2577) (out= 1282)(deflated 50%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/Hangul$DoubleCoda$.class(in = 2155) (out= 963)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanConjugation$.class(in = 22440) (out= 7972)(deflated 64%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie$.class(in = 3157) (out= 1089)(deflated 65%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/typos/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/typos/typos.txt(in = 5146) (out= 2300)(deflated 55%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanDictionaryProvider$.class(in = 20197) (out= 7488)(deflated 62%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/substantives/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/substantives/given_names.txt(in = 1407) (out= 609)(deflated 56%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/substantives/suffix.txt(in = 325) (out= 224)(deflated 31%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/substantives/family_names.txt(in = 299) (out= 197)(deflated 34%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/substantives/modifier.txt(in = 3395) (out= 1346)(deflated 60%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/adverb/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/adverb/adverb.txt(in = 65572) (out= 18741)(deflated 71%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanDictionaryProvider.class(in = 3430) (out= 2003)(deflated 41%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/CharacterUtils.class(in = 3703) (out= 1716)(deflated 53%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/KoreanPos$KoreanPosTrie.class(in = 4390) (out= 1610)(deflated 63%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/auxiliary/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/auxiliary/exclamation.txt(in = 1759) (out= 757)(deflated 56%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/auxiliary/determiner.txt(in = 63) (out= 63)(deflated 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/util/auxiliary/conjunctions.txt(in = 398) (out= 189)(deflated 52%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/KoreanProcessorSandbox.class(in = 824) (out= 575)(deflated 30%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchTokenizeTweets.class(in = 2720) (out= 2031)(deflated 25%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/KoreanProcessorSandbox$.class(in = 1464) (out= 823)(deflated 43%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime$.class(in = 2418) (out= 1015)(deflated 58%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchTokenizeTweets$.class(in = 10867) (out= 4401)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchGetUnknownNouns$.class(in = 8751) (out= 3532)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet.class(in = 3080) (out= 1338)(deflated 56%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchTokenizeTweets$ParseTime.class(in = 3153) (out= 1446)(deflated 54%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchGetUnknownNouns.class(in = 2307) (out= 1702)(deflated 26%)\n",
            "adding: new_dic/org/openkoreantext/processor/qa/BatchGetUnknownNouns$ChunkWithTweet$.class(in = 2376) (out= 952)(deflated 59%)\n",
            "adding: new_dic/org/openkoreantext/processor/KoreanTokenJava.class(in = 1976) (out= 931)(deflated 52%)\n",
            "adding: new_dic/META-INF/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/META-INF/MANIFEST.MF(in = 133) (out= 111)(deflated 16%)\n",
            "adding: new_dic/META-INF/maven/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/META-INF/maven/org.openkoreantext/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/META-INF/maven/org.openkoreantext/open-korean-text/(in = 0) (out= 0)(stored 0%)\n",
            "adding: new_dic/META-INF/maven/org.openkoreantext/open-korean-text/pom.xml(in = 9127) (out= 2208)(deflated 75%)\n",
            "adding: new_dic/META-INF/maven/org.openkoreantext/open-korean-text/pom.properties(in = 119) (out= 110)(deflated 7%)\n",
            "adding: open-korean-text-2.1.0.jar(in = 1736895) (out= 1715972)(deflated 1%)\n",
            "adding: scala-library-2.12.3.jar(in = 5246851) (out= 4880676)(deflated 6%)\n",
            "adding: shineware-common-1.0.jar(in = 39039) (out= 34907)(deflated 10%)\n",
            "adding: shineware-ds-1.0.jar(in = 14396) (out= 11874)(deflated 17%)\n",
            "adding: snakeyaml-1.12.jar(in = 270779) (out= 236161)(deflated 12%)\n",
            "adding: twitter-text-1.14.7.jar(in = 50722) (out= 47116)(deflated 7%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()\n",
        "os.chdir('/content/')"
      ],
      "metadata": {
        "id": "1iZvKc0ehKTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Keyword(label_):\n",
        "  x = len(testdata['Pred'])\n",
        "  word = []\n",
        "  review_lst=[]\n",
        "  for i in range(x):\n",
        "    if testdata['Pred'][i]==label_:\n",
        "      new_sentence = testdata['comment'][i]\n",
        "      new_sentence = okt.pos(new_sentence, stem = True)\n",
        "      y = len(new_sentence)\n",
        "      for i in range(y):\n",
        "        if new_sentence[i][1]== 'Noun':\n",
        "          p = len(new_sentence[i][0])\n",
        "          if p > 1:\n",
        "            word.append(new_sentence[i][0])\n",
        "  count_noun = Counter(word)\n",
        "  max_num = count_noun.most_common(n=10)\n",
        "  print(max_num)"
      ],
      "metadata": {
        "id": "yxArGKiChNDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Keyword(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFpDcsOohR1v",
        "outputId": "259fee4c-59f2-4109-cd68-0754dd2fcb37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('정말', 18), ('사용', 15), ('제품', 9), ('노트북', 8), ('가성', 7), ('배터리', 7), ('정도', 7), ('휴대', 6), ('가격', 6), ('생각', 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Keyword2(label_):\n",
        "  x = len(datax['label'])\n",
        "  word = []\n",
        "  review_lst=[]\n",
        "  for i in range(x):\n",
        "    if datax['label'][i]==label_:\n",
        "      new_sentence = datax['comment'][i]\n",
        "      new_sentence = okt.pos(new_sentence, stem = True)\n",
        "      y = len(new_sentence)\n",
        "      for i in range(y):\n",
        "        if new_sentence[i][1]== 'Noun':\n",
        "          p = len(new_sentence[i][0])\n",
        "          if p > 1:\n",
        "            word.append(new_sentence[i][0])\n",
        "  count_noun = Counter(word)\n",
        "  max_num = count_noun.most_common(n=30)\n",
        "  print(max_num)"
      ],
      "metadata": {
        "id": "7SNn8ewnh0sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Keyword2(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRLBlDg3jEeT",
        "outputId": "0e81e4d7-757b-4121-a4b1-d210d06301a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('삼성', 1160), ('진짜', 912), ('제품', 777), ('아이폰', 756), ('그냥', 710), ('가격', 668), ('애플', 646), ('생각', 584), ('프로', 574), ('디자인', 562), ('사용', 561), ('카메라', 552), ('센터', 546), ('배송', 485), ('노트', 473), ('서비스', 462), ('갤럭시', 424), ('구매', 415), ('정도', 402), ('불량', 385), ('성능', 373), ('화면', 356), ('노치', 355), ('사람', 343), ('별로', 343), ('이번', 336), ('문제', 328), ('느낌', 322), ('혁신', 311), ('배터리', 310)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Keyword2(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_102PlTWjaUM",
        "outputId": "67e6e67b-c76a-4bda-a10e-3fad8fddd680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('사용', 5136), ('구매', 3736), ('배송', 3551), ('제품', 2791), ('노트북', 2571), ('버즈', 2518), ('생각', 2484), ('프로', 2465), ('진짜', 2321), ('갤럭시', 2223), ('기능', 2047), ('디자인', 1899), ('가격', 1883), ('정말', 1860), ('삼성', 1727), ('정도', 1505), ('고민', 1489), ('케이스', 1408), ('화면', 1398), ('성능', 1374), ('이어폰', 1326), ('음질', 1313), ('아이폰', 1273), ('색상', 1244), ('소리', 1236), ('구입', 1200), ('이번', 1165), ('주문', 1107), ('애플', 1104), ('바로', 1092)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Keyword2(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sraqXkQwjbmw",
        "outputId": "fd3e77fa-a969-4863-ac21-d57e17ac4b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('가격', 488), ('사용', 471), ('제품', 469), ('배송', 450), ('생각', 382), ('프로', 371), ('진짜', 354), ('디자인', 328), ('구매', 290), ('아이폰', 281), ('삼성', 271), ('애플', 270), ('그냥', 263), ('배터리', 260), ('버즈', 248), ('고민', 247), ('기능', 246), ('음질', 232), ('정도', 231), ('갤럭시', 230), ('카메라', 220), ('성능', 209), ('소리', 202), ('센터', 195), ('조금', 194), ('문제', 190), ('느낌', 176), ('케이스', 175), ('때문', 167), ('화면', 166)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datax = pd.read_excel('/content/리뷰_데이터_최종.xlsx')\n",
        "datax.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AMFs9GXtirws",
        "outputId": "698ee97d-5170-45dc-f9c2-5b1317d68141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                            comment\n",
              "0      0  메종키츠네 테마 폴드3에서는 적용 불가네요;;; 제일 비싼 라인업에서 사용 불가라니...\n",
              "1      1                                          진짜 너무 이쁘다\n",
              "2      1                                           아 너무 예쁘당\n",
              "3      1  솔직히 이거는 돈 하나도 안아까울듯  브랜드 이미지만 있어도 충분히 감성적일텐데, ...\n",
              "4      1       진짜 너무 예쁘네요ㅠㅠ 워치랑 버즈도 이쁜데 폰 테마 진짜 대박. 너무 이뻐요."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74ab005a-b24d-4726-a1b5-4864e8dfcdd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>메종키츠네 테마 폴드3에서는 적용 불가네요;;; 제일 비싼 라인업에서 사용 불가라니...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>진짜 너무 이쁘다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>아 너무 예쁘당</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>솔직히 이거는 돈 하나도 안아까울듯  브랜드 이미지만 있어도 충분히 감성적일텐데, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>진짜 너무 예쁘네요ㅠㅠ 워치랑 버즈도 이쁜데 폰 테마 진짜 대박. 너무 이뻐요.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74ab005a-b24d-4726-a1b5-4864e8dfcdd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74ab005a-b24d-4726-a1b5-4864e8dfcdd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74ab005a-b24d-4726-a1b5-4864e8dfcdd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    }
  ]
}